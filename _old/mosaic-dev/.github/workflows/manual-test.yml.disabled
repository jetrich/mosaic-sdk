name: Manual Test Runner

on:
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of tests to run'
        required: true
        type: choice
        options:
          - unit
          - integration
          - e2e
          - performance
          - security
          - all
        default: 'unit'
      
      test_scope:
        description: 'Scope of tests'
        required: true
        type: choice
        options:
          - backend
          - frontend
          - full-stack
        default: 'full-stack'
      
      environment:
        description: 'Test environment'
        required: false
        type: choice
        options:
          - local
          - staging
          - production
        default: 'local'
      
      browser:
        description: 'Browser for E2E tests'
        required: false
        type: choice
        options:
          - chromium
          - firefox
          - webkit
          - all
        default: 'chromium'
      
      parallel:
        description: 'Run tests in parallel'
        required: false
        type: boolean
        default: true
      
      coverage:
        description: 'Generate coverage report'
        required: false
        type: boolean
        default: true

env:
  NODE_VERSION: '18'

jobs:
  setup:
    name: Test Setup
    runs-on: ubuntu-latest
    outputs:
      test-matrix: ${{ steps.matrix.outputs.matrix }}
      run-id: ${{ steps.run.outputs.run-id }}
    steps:
      - name: Generate run ID
        id: run
        run: |
          RUN_ID="test-run-$(date +%s)"
          echo "run-id=$RUN_ID" >> $GITHUB_OUTPUT
          echo "Generated test run ID: $RUN_ID"

      - name: Generate test matrix
        id: matrix
        run: |
          TEST_TYPE="${{ github.event.inputs.test_type }}"
          TEST_SCOPE="${{ github.event.inputs.test_scope }}"
          BROWSER="${{ github.event.inputs.browser }}"
          
          if [ "$TEST_TYPE" == "all" ]; then
            TYPES='["unit", "integration", "e2e", "performance", "security"]'
          else
            TYPES='["${{ github.event.inputs.test_type }}"]'
          fi
          
          if [ "$TEST_SCOPE" == "full-stack" ]; then
            SCOPES='["backend", "frontend"]'
          else
            SCOPES='["${{ github.event.inputs.test_scope }}"]'
          fi
          
          if [ "$BROWSER" == "all" ]; then
            BROWSERS='["chromium", "firefox", "webkit"]'
          else
            BROWSERS='["${{ github.event.inputs.browser }}"]'
          fi
          
          MATRIX=$(jq -n \
            --argjson types "$TYPES" \
            --argjson scopes "$SCOPES" \
            --argjson browsers "$BROWSERS" \
            '{
              "test_type": $types,
              "scope": $scopes,
              "browser": $browsers
            }')
          
          echo "matrix=$MATRIX" >> $GITHUB_OUTPUT
          echo "Generated test matrix: $MATRIX"

  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: setup
    if: contains(fromJson(needs.setup.outputs.test-matrix).test_type, 'unit')
    strategy:
      matrix:
        scope: ${{ fromJson(needs.setup.outputs.test-matrix).scope }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: '**/package-lock.json'

      - name: Install dependencies
        run: |
          if [ "${{ matrix.scope }}" == "backend" ]; then
            cd backend && npm ci
          elif [ "${{ matrix.scope }}" == "frontend" ]; then
            cd frontend && npm ci
          fi

      - name: Run unit tests
        run: |
          echo "Running unit tests for ${{ matrix.scope }}..."
          
          if [ "${{ matrix.scope }}" == "backend" ]; then
            cd backend
            if [ "${{ github.event.inputs.coverage }}" == "true" ]; then
              npm run test:cov
            else
              npm run test
            fi
          elif [ "${{ matrix.scope }}" == "frontend" ]; then
            cd frontend
            if [ "${{ github.event.inputs.coverage }}" == "true" ]; then
              npm run test:coverage
            else
              npm run test
            fi
          fi

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unit-test-results-${{ matrix.scope }}-${{ needs.setup.outputs.run-id }}
          path: |
            ${{ matrix.scope }}/coverage/
            ${{ matrix.scope }}/test-results.xml
          retention-days: 7

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: setup
    if: contains(fromJson(needs.setup.outputs.test-matrix).test_type, 'integration')
    services:
      postgres:
        image: postgres:17-alpine
        env:
          POSTGRES_DB: tony_ng_test
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:8-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 3s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm run install:all

      - name: Setup test database
        run: |
          cd backend
          npm run migration:run
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/tony_ng_test

      - name: Run integration tests
        run: npm run test:integration
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/tony_ng_test
          REDIS_URL: redis://localhost:6379
          NODE_ENV: test

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: integration-test-results-${{ needs.setup.outputs.run-id }}
          path: |
            tests/integration/results/
            coverage/integration/
          retention-days: 7

  e2e-tests:
    name: E2E Tests
    runs-on: ubuntu-latest
    needs: setup
    if: contains(fromJson(needs.setup.outputs.test-matrix).test_type, 'e2e')
    strategy:
      matrix:
        browser: ${{ fromJson(needs.setup.outputs.test-matrix).browser }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm run install:all

      - name: Install Playwright browsers
        run: npx playwright install --with-deps ${{ matrix.browser }}

      - name: Build applications
        run: npm run build

      - name: Start test environment
        if: github.event.inputs.environment == 'local'
        run: |
          docker compose up -d
          sleep 30

      - name: Run E2E tests
        run: |
          if [ "${{ github.event.inputs.environment }}" == "local" ]; then
            npx playwright test --project=${{ matrix.browser }}
          else
            # Run against staging/production
            PLAYWRIGHT_TEST_BASE_URL="https://${{ github.event.inputs.environment }}.tony-ng.com" \
            npx playwright test --project=${{ matrix.browser }}
          fi

      - name: Upload E2E test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-test-results-${{ matrix.browser }}-${{ needs.setup.outputs.run-id }}
          path: |
            test-results/
            playwright-report/
          retention-days: 7

  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: setup
    if: contains(fromJson(needs.setup.outputs.test-matrix).test_type, 'performance')
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install k6
        run: |
          sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: Start test environment
        if: github.event.inputs.environment == 'local'
        run: |
          docker compose up -d
          sleep 30

      - name: Run performance tests
        run: |
          if [ "${{ github.event.inputs.environment }}" == "local" ]; then
            k6 run tests/performance/load-test.js --out json=performance-results.json
          else
            # Run against staging/production with lighter load
            k6 run tests/performance/${{ github.event.inputs.environment }}-test.js --out json=performance-results.json
          fi

      - name: Upload performance results
        uses: actions/upload-artifact@v4
        with:
          name: performance-test-results-${{ needs.setup.outputs.run-id }}
          path: performance-results.json
          retention-days: 7

  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    needs: setup
    if: contains(fromJson(needs.setup.outputs.test-matrix).test_type, 'security')
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm run install:all

      - name: Run security tests
        run: |
          echo "Running security tests..."
          
          # Dependency audit
          npm audit --audit-level=moderate
          
          # SAST analysis
          npx semgrep --config=auto --json --output=semgrep-results.json .
          
          # Secret detection
          echo "Running secret detection..."

      - name: Upload security results
        uses: actions/upload-artifact@v4
        with:
          name: security-test-results-${{ needs.setup.outputs.run-id }}
          path: |
            semgrep-results.json
            audit-results.json
          retention-days: 7

  test-report:
    name: Test Report
    runs-on: ubuntu-latest
    needs: [setup, unit-tests, integration-tests, e2e-tests, performance-tests, security-tests]
    if: always()
    steps:
      - name: Download all test results
        uses: actions/download-artifact@v4
        with:
          path: ./test-results

      - name: Generate test report
        run: |
          echo "## Manual Test Run Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Run ID**: ${{ needs.setup.outputs.run-id }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Test Type**: ${{ github.event.inputs.test_type }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Test Scope**: ${{ github.event.inputs.test_scope }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Environment**: ${{ github.event.inputs.environment }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Browser**: ${{ github.event.inputs.browser }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Parallel**: ${{ github.event.inputs.parallel }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Coverage**: ${{ github.event.inputs.coverage }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Initiated by**: ${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Results" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ needs.unit-tests.result }}" != "skipped" ]; then
            if [ "${{ needs.unit-tests.result }}" == "success" ]; then
              echo "✅ **Unit Tests**: Passed" >> $GITHUB_STEP_SUMMARY
            else
              echo "❌ **Unit Tests**: Failed" >> $GITHUB_STEP_SUMMARY
            fi
          fi
          
          if [ "${{ needs.integration-tests.result }}" != "skipped" ]; then
            if [ "${{ needs.integration-tests.result }}" == "success" ]; then
              echo "✅ **Integration Tests**: Passed" >> $GITHUB_STEP_SUMMARY
            else
              echo "❌ **Integration Tests**: Failed" >> $GITHUB_STEP_SUMMARY
            fi
          fi
          
          if [ "${{ needs.e2e-tests.result }}" != "skipped" ]; then
            if [ "${{ needs.e2e-tests.result }}" == "success" ]; then
              echo "✅ **E2E Tests**: Passed" >> $GITHUB_STEP_SUMMARY
            else
              echo "❌ **E2E Tests**: Failed" >> $GITHUB_STEP_SUMMARY
            fi
          fi
          
          if [ "${{ needs.performance-tests.result }}" != "skipped" ]; then
            if [ "${{ needs.performance-tests.result }}" == "success" ]; then
              echo "✅ **Performance Tests**: Passed" >> $GITHUB_STEP_SUMMARY
            else
              echo "❌ **Performance Tests**: Failed" >> $GITHUB_STEP_SUMMARY
            fi
          fi
          
          if [ "${{ needs.security-tests.result }}" != "skipped" ]; then
            if [ "${{ needs.security-tests.result }}" == "success" ]; then
              echo "✅ **Security Tests**: Passed" >> $GITHUB_STEP_SUMMARY
            else
              echo "❌ **Security Tests**: Failed" >> $GITHUB_STEP_SUMMARY
            fi
          fi

      - name: Create detailed report
        run: |
          cat > detailed-test-report.json << EOF
          {
            "run_id": "${{ needs.setup.outputs.run-id }}",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "inputs": {
              "test_type": "${{ github.event.inputs.test_type }}",
              "test_scope": "${{ github.event.inputs.test_scope }}",
              "environment": "${{ github.event.inputs.environment }}",
              "browser": "${{ github.event.inputs.browser }}",
              "parallel": ${{ github.event.inputs.parallel }},
              "coverage": ${{ github.event.inputs.coverage }}
            },
            "results": {
              "unit_tests": "${{ needs.unit-tests.result }}",
              "integration_tests": "${{ needs.integration-tests.result }}",
              "e2e_tests": "${{ needs.e2e-tests.result }}",
              "performance_tests": "${{ needs.performance-tests.result }}",
              "security_tests": "${{ needs.security-tests.result }}"
            },
            "initiated_by": "${{ github.actor }}"
          }
          EOF

      - name: Upload detailed report
        uses: actions/upload-artifact@v4
        with:
          name: detailed-test-report-${{ needs.setup.outputs.run-id }}
          path: detailed-test-report.json
          retention-days: 30