#!/bin/bash

# Tony Framework - Automated Task Hierarchy Management System (ATHMS)
# Implements ultrathink planning protocol with persistent task tracking

set -euo pipefail

# Script configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# Source shared utilities
source "$SCRIPT_DIR/shared/logging-utils.sh"

# Configuration
TASK_ROOT="docs/task-management"
PLANNING_DIR="$TASK_ROOT/planning"
ACTIVE_DIR="$TASK_ROOT/active"
COMPLETED_DIR="$TASK_ROOT/completed"
TEMPLATES_DIR="$TASK_ROOT/templates"
MODE=""
VERBOSE=false
AUTO_CONFIRM=false

# Display usage information
show_usage() {
    show_banner "Tony Automated Task Hierarchy Management System" "Ultrathink planning with persistent task tracking"
    
    echo "Usage: $0 [COMMAND] [OPTIONS]"
    echo ""
    echo "Planning Commands:"
    echo "  plan start                    Execute FULL Ultrathink Planning Protocol (UPP)"
    echo "  plan continue                 Continue UPP from current phase"
    echo "  plan abstract                 Create first-level task abstraction (EPICs)"
    echo "  plan decompose <epic-id>      Decompose specific EPIC to atomic level"
    echo "  plan second-pass              Execute second pass gap analysis"
    echo "  plan validate                 Validate planning completeness"
    echo "  plan metrics                  Show decomposition statistics"
    echo ""
    echo "Task Commands:"
    echo "  task create <task-id> <desc>  Create new task with workspace"
    echo "  task status [task-id]         Show task status and dependencies"
    echo "  task assign <task-id> <agent> Assign task to agent"
    echo "  task claim <task-id>          Claim task ownership"
    echo "  task update <task-id> <status> Update task progress"
    echo "  task complete <task-id>       Submit completion with evidence"
    echo "  task validate <task-id>       QA validation of completion"
    echo "  task recover                  Recover failed/stuck tasks"
    echo "  task next                     Get next available task"
    echo ""
    echo "Management Commands:"
    echo "  init                          Initialize ATHMS in current project"
    echo "  status                        Show overall project task status"
    echo "  backup                        Create comprehensive state backup"
    echo "  restore <backup-path>         Restore state from backup"
    echo "  validate                      Validate and repair state integrity"
    echo "  emergency                     Emergency state recovery protocol"
    echo "  report                        Generate progress reports"
    echo "  cleanup                       Clean up completed tasks"
    echo "  security                      Deploy enterprise security controls"
    echo "  force-upgrade                 Force upgrade all projects to v2.2.0 standards"
    echo ""
    echo "Options:"
    echo "  --verbose                     Enable verbose output"
    echo "  --auto-confirm                Skip confirmation prompts"
    echo "  --help                        Show this help message"
    echo ""
    echo "Examples:"
    echo "  $0 init                       # Initialize task management"
    echo "  $0 plan start                 # Begin ultrathink planning"
    echo "  $0 task create 1.001.01.01 'Setup database'"
    echo "  $0 task claim 1.001.01.01     # Claim task for work"
}

# Parse command line arguments
parse_arguments() {
    if [ $# -eq 0 ]; then
        show_usage
        exit 1
    fi
    
    MODE="$1"
    shift
    
    # Store remaining arguments for command processing
    ARGS=("$@")
    
    # Process options
    while [[ $# -gt 0 ]]; do
        case $1 in
            --verbose)
                VERBOSE=true
                enable_verbose
                ;;
            --auto-confirm)
                AUTO_CONFIRM=true
                ;;
            --help)
                show_usage
                exit 0
                ;;
            --*)
                log_error "Unknown option: $1"
                exit 1
                ;;
            *)
                # Non-option argument, keep it for command processing
                ;;
        esac
        shift
    done
}

# Initialize ATHMS directory structure
init_athms() {
    print_section "Initializing Automated Task Hierarchy Management System"
    
    # Create directory structure
    local dirs=(
        "$TASK_ROOT"
        "$PLANNING_DIR"
        "$PLANNING_DIR/phase-1-abstraction" 
        "$PLANNING_DIR/phase-2-decomposition"
        "$PLANNING_DIR/phase-3-second-pass"
        "$ACTIVE_DIR"
        "$COMPLETED_DIR"
        "$TEMPLATES_DIR"
        "$TASK_ROOT/logs"
        "$TASK_ROOT/reports"
        "$TASK_ROOT/metrics"
    )
    
    for dir in "${dirs[@]}"; do
        if [ ! -d "$dir" ]; then
            mkdir -p "$dir"
            log_success "Created directory: $dir"
        else
            log_debug "Directory exists: $dir"
        fi
    done
    
    # Create templates
    create_task_templates
    
    # Initialize planning state
    init_planning_state
    
    # Create initial configuration
    create_athms_config
    
    log_success "ATHMS initialization complete"
}

# Create task templates
create_task_templates() {
    local task_template="$TEMPLATES_DIR/task.json"
    local status_template="$TEMPLATES_DIR/status.json"
    local dependencies_template="$TEMPLATES_DIR/dependencies.json"
    
    # Task metadata template
    if [ ! -f "$task_template" ]; then
        cat > "$task_template" << 'EOF'
{
  "task_id": "",
  "title": "",
  "description": "",
  "objective": "",
  "success_criteria": [],
  "duration_estimate_minutes": 30,
  "complexity": "atomic",
  "files_affected": [],
  "testing_requirements": [],
  "created_at": "",
  "created_by": "tony-framework",
  "parent_task": null,
  "child_tasks": [],
  "tags": [],
  "notes": ""
}
EOF
        log_debug "Created task template: $task_template"
    fi
    
    # Status tracking template
    if [ ! -f "$status_template" ]; then
        cat > "$status_template" << 'EOF'
{
  "task_id": "",
  "status": "pending",
  "assigned_agent": null,
  "progress_percentage": 0,
  "time_spent_minutes": 0,
  "started_at": null,
  "last_updated": "",
  "completion_claimed_at": null,
  "validated_at": null,
  "blocked": false,
  "blocking_reason": null,
  "attempts": 0,
  "failure_count": 0,
  "last_failure_reason": null,
  "workspace_path": "",
  "evidence_submitted": false,
  "validation_passed": false
}
EOF
        log_debug "Created status template: $status_template"
    fi
    
    # Dependencies template
    if [ ! -f "$dependencies_template" ]; then
        cat > "$dependencies_template" << 'EOF'
{
  "task_id": "",
  "prerequisites": [],
  "blocks": [],
  "related_tasks": [],
  "external_dependencies": [],
  "dependency_status": "ready",
  "waiting_for": [],
  "last_dependency_check": ""
}
EOF
        log_debug "Created dependencies template: $dependencies_template"
    fi
}

# Initialize planning state
init_planning_state() {
    local planning_state="$PLANNING_DIR/planning-state.json"
    
    if [ ! -f "$planning_state" ]; then
        cat > "$planning_state" << EOF
{
  "project_name": "$(basename "$(pwd)")",
  "planning_started_at": "$(date -Iseconds)",
  "current_phase": "not_started",
  "phases": {
    "phase_1_abstraction": {
      "status": "not_started",
      "completed_at": null,
      "tree_count": 0
    },
    "phase_2_decomposition": {
      "status": "not_started", 
      "completed_at": null,
      "trees_processed": [],
      "current_tree": null
    },
    "phase_3_second_pass": {
      "status": "not_started",
      "completed_at": null,
      "gaps_identified": 0,
      "tasks_added": 0
    }
  },
  "ultrathink_rules": {
    "single_tree_focus": true,
    "complete_before_continue": true,
    "no_premature_optimization": true,
    "no_implementation_planning": true
  },
  "metrics": {
    "total_tasks_planned": 0,
    "atomic_tasks": 0,
    "micro_tasks": 0,
    "planning_time_minutes": 0
  }
}
EOF
        log_debug "Created planning state: $planning_state"
    fi
}

# Create ATHMS configuration
create_athms_config() {
    local config_file="$TASK_ROOT/athms-config.json"
    
    if [ ! -f "$config_file" ]; then
        cat > "$config_file" << EOF
{
  "version": "1.0.0",
  "project_root": "$(pwd)",
  "task_numbering": {
    "format": "P.TTT.SS.AA.MM",
    "phase_digits": 1,
    "task_digits": 3,
    "subtask_digits": 2,
    "atomic_digits": 2,
    "micro_digits": 2
  },
  "automation": {
    "auto_assign_dependencies": true,
    "validate_completions": true,
    "auto_recover_failed_tasks": true,
    "git_integration": true
  },
  "quality_gates": {
    "max_task_duration_minutes": 30,
    "require_evidence": true,
    "require_validation": true,
    "min_success_criteria": 1
  },
  "agent_coordination": {
    "max_concurrent_agents": 5,
    "prevent_resource_conflicts": true,
    "require_handoff_documentation": true
  }
}
EOF
        log_debug "Created ATHMS config: $config_file"
    fi
}

# Start ultrathink planning protocol - FULL UPP EXECUTION
start_planning() {
    print_section "Starting Complete Ultrathink Planning Protocol (UPP)"
    
    # Verify ATHMS is initialized
    if [ ! -d "$TASK_ROOT" ]; then
        log_info "ATHMS not initialized. Initializing now..."
        init_athms
    fi
    
    local planning_state="$PLANNING_DIR/planning-state.json"
    local current_phase
    current_phase=$(jq -r '.current_phase' "$planning_state")
    
    if [ "$current_phase" != "not_started" ]; then
        log_warning "Planning already in progress. Current phase: $current_phase"
        if [ "$AUTO_CONFIRM" != true ]; then
            read -p "Continue with current phase? (y/N): " confirm
            if [[ ! "$confirm" =~ ^[Yy]$ ]]; then
                exit 0
            fi
        fi
    fi
    
    log_info "üß† FULL ULTRATHINK PLANNING PROTOCOL (UPP) EXECUTION"
    echo ""
    echo "üìã UPP HIERARCHY FORMAT:"
    echo "PROJECT (P)"
    echo "‚îú‚îÄ‚îÄ EPIC (E.XXX)"
    echo "‚îÇ   ‚îú‚îÄ‚îÄ FEATURE (F.XXX.XX)"
    echo "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ STORY (S.XXX.XX.XX)"
    echo "‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ TASK (T.XXX.XX.XX.XX)"
    echo "‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SUBTASK (ST.XXX.XX.XX.XX.XX)"
    echo "‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ATOMIC (A.XXX.XX.XX.XX.XX.XX) [‚â§30 min]"
    echo ""
    echo "üìÅ All planning documents will be stored in: docs/task-management/planning/"
    echo ""
    
    # Execute Phase 1: First-Level Abstraction
    log_info "üéØ Phase 1: First-Level Abstraction (Creating EPICs)"
    jq '.current_phase = "phase_1_abstraction" | .phases.phase_1_abstraction.status = "in_progress"' "$planning_state" > "$planning_state.tmp"
    mv "$planning_state.tmp" "$planning_state"
    
    create_abstraction
    
    # Execute Phase 2: Sequential Tree Processing (if abstraction completed)
    local phase1_status
    phase1_status=$(jq -r '.phases.phase_1_abstraction.status' "$planning_state")
    
    if [ "$phase1_status" = "completed" ]; then
        log_info "üéØ Phase 2: Sequential Tree Decomposition"
        
        # Get tree count and decompose each tree sequentially
        local tree_count
        tree_count=$(jq -r '.phases.phase_1_abstraction.tree_count' "$planning_state")
        
        for ((i=1; i<=tree_count; i++)); do
            local tree_id="E.$(printf "%03d" $i)"
            log_info "üå≥ Decomposing Epic $tree_id..."
            decompose_tree "$tree_id"
        done
        
        # Execute Phase 3: Second Pass Gap Analysis
        log_info "üéØ Phase 3: Second Pass Gap Analysis"
        second_pass_analysis
        
        # Show final results
        log_success "üéâ COMPLETE ULTRATHINK PLANNING PROTOCOL FINISHED"
        echo ""
        show_planning_metrics
        
    else
        log_info "Complete Phase 1 abstraction, then run: $0 plan continue"
    fi
}

# Continue planning from current phase
continue_planning() {
    local planning_state="$PLANNING_DIR/planning-state.json"
    
    if [ ! -f "$planning_state" ]; then
        log_error "No planning state found. Run: $0 plan start"
        exit 1
    fi
    
    local current_phase
    current_phase=$(jq -r '.current_phase' "$planning_state")
    
    case "$current_phase" in
        "not_started")
            log_info "No planning started. Running full UPP..."
            start_planning
            ;;
        "phase_1_abstraction")
            log_info "Continuing Phase 1: Abstraction"
            create_abstraction
            ;;
        "phase_2_decomposition")
            log_info "Continuing Phase 2: Tree Decomposition"
            # Continue with remaining trees
            local tree_count processed_count
            tree_count=$(jq -r '.phases.phase_1_abstraction.tree_count' "$planning_state")
            processed_count=$(jq -r '.phases.phase_2_decomposition.trees_processed | length' "$planning_state")
            
            for ((i=processed_count+1; i<=tree_count; i++)); do
                local tree_id="E.$(printf "%03d" $i)"
                log_info "üå≥ Decomposing Epic $tree_id..."
                decompose_tree "$tree_id"
            done
            
            # Move to phase 3
            log_info "üéØ Phase 3: Second Pass Gap Analysis"
            second_pass_analysis
            ;;
        "phase_3_second_pass")
            log_info "Continuing Phase 3: Gap Analysis"
            second_pass_analysis
            ;;
        "planning_complete")
            log_info "Planning already complete"
            show_planning_metrics
            ;;
        *)
            log_error "Unknown planning phase: $current_phase"
            exit 1
            ;;
    esac
}

# Create first-level abstraction
create_abstraction() {
    print_section "Phase 1: First-Level Task Abstraction (EPICs)"
    
    local abstraction_file="$PLANNING_DIR/phase-1-abstraction/task-trees.md"
    local planning_state="$PLANNING_DIR/planning-state.json"
    
    # Check if already completed
    local phase_status
    phase_status=$(jq -r '.phases.phase_1_abstraction.status' "$planning_state")
    
    if [ "$phase_status" = "completed" ]; then
        log_warning "Phase 1 abstraction already completed"
        cat "$abstraction_file"
        return 0
    fi
    
    mkdir -p "$(dirname "$abstraction_file")"
    
    echo "üìù Create your first-level task abstraction (EPICs) below:"
    echo "Use format: E.XXX - Epic Name (High Level Category)"
    echo "Press Ctrl+D when finished, or Ctrl+C to cancel"
    echo ""
    echo "üìã UPP HIERARCHY REMINDER:"
    echo "PROJECT (P)"
    echo "‚îú‚îÄ‚îÄ EPIC (E.XXX) ‚Üê You are creating these now"
    echo "‚îÇ   ‚îú‚îÄ‚îÄ FEATURE (F.XXX.XX)"
    echo "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ STORY (S.XXX.XX.XX)"
    echo "‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ TASK (T.XXX.XX.XX.XX)"
    echo "‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SUBTASK (ST.XXX.XX.XX.XX.XX)"
    echo "‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ATOMIC (A.XXX.XX.XX.XX.XX.XX) [‚â§30 min]"
    echo ""
    
    # Create abstraction file with template
    cat > "$abstraction_file" << 'EOF'
# Phase 1: First-Level Task Abstraction (EPICs)
# Rules: High-level categories only, no decomposition yet
# Format: E.XXX - Epic Name
# Location: docs/task-management/planning/ (consistent across all Tony projects)

## Project EPICs

E.001 - [Your first epic here]
E.002 - [Your second epic here]
E.003 - [Your third epic here]

# Example EPICs:
# E.001 - Project Foundation & Setup
# E.002 - Core Feature Development  
# E.003 - Quality Assurance & Testing
# E.004 - Deployment & Operations
# E.005 - Documentation & User Experience

EOF
    
    # Let user edit the file
    if command -v nano >/dev/null 2>&1; then
        nano "$abstraction_file"
    elif command -v vim >/dev/null 2>&1; then
        vim "$abstraction_file"
    else
        log_error "No editor available. Please edit manually: $abstraction_file"
        return 1
    fi
    
    # Validate abstraction
    local tree_count
    tree_count=$(grep -c '^E\.[0-9]\+' "$abstraction_file" || echo "0")
    
    if [ "$tree_count" -eq 0 ]; then
        log_error "No EPICs found. Please add at least one EPIC using format: E.XXX - Epic Name"
        return 1
    fi
    
    # Update planning state
    jq ".phases.phase_1_abstraction.status = \"completed\" | 
        .phases.phase_1_abstraction.completed_at = \"$(date -Iseconds)\" |
        .phases.phase_1_abstraction.tree_count = $tree_count |
        .current_phase = \"phase_2_decomposition\"" "$planning_state" > "$planning_state.tmp"
    mv "$planning_state.tmp" "$planning_state"
    
    log_success "Phase 1 completed: $tree_count EPICs identified"
    echo ""
    echo "üìä EPICs Created:"
    grep '^E\.[0-9]\+' "$abstraction_file" | sed 's/^/  /'
    echo ""
    echo "‚úÖ Documentation stored in: docs/task-management/planning/"
    echo ""
    echo "Next step: Automated sequential decomposition will begin..."
}

# Decompose specific task tree
decompose_tree() {
    local tree_id="$1"
    
    if [ -z "$tree_id" ]; then
        log_error "Tree ID required. Example: $0 plan decompose 1.000"
        exit 1
    fi
    
    print_section "Phase 2: Sequential Tree Decomposition - $tree_id"
    
    local planning_state="$PLANNING_DIR/planning-state.json"
    local abstraction_file="$PLANNING_DIR/phase-1-abstraction/task-trees.md"
    local decomposition_file="$PLANNING_DIR/phase-2-decomposition/tree-${tree_id}-decomposition.md"
    
    # Validate tree exists in abstraction
    if ! grep -q "^${tree_id}" "$abstraction_file"; then
        log_error "Tree $tree_id not found in abstraction. Available trees:"
        grep '^[0-9]\+\.000' "$abstraction_file" | sed 's/^/  /'
        exit 1
    fi
    
    # Check if tree already processed
    local processed_trees
    processed_trees=$(jq -r '.phases.phase_2_decomposition.trees_processed[]' "$planning_state" 2>/dev/null || echo "")
    
    if echo "$processed_trees" | grep -q "^$tree_id$"; then
        log_warning "Tree $tree_id already decomposed"
        if [ -f "$decomposition_file" ]; then
            cat "$decomposition_file"
        fi
        return 0
    fi
    
    # Get tree description
    local tree_desc
    tree_desc=$(grep "^${tree_id}" "$abstraction_file" | cut -d'-' -f2- | xargs)
    
    log_info "Decomposing tree: $tree_id - $tree_desc"
    echo ""
    echo "üå≥ DECOMPOSITION RULES:"
    echo "1. Process this tree to MICRO-TASK level completely"
    echo "2. Do NOT work on other trees until this is 100% complete"
    echo "3. Use hierarchical numbering: $tree_id -> ${tree_id%.000}.001 -> ${tree_id%.000}.001.01 -> ${tree_id%.000}.001.01.01"
    echo "4. Atomic tasks ‚â§30 minutes, micro tasks ‚â§10 minutes"
    echo "5. Include dependencies, success criteria, and testing requirements"
    echo ""
    
    mkdir -p "$(dirname "$decomposition_file")"
    
    # Create decomposition template
    cat > "$decomposition_file" << EOF
# Tree $tree_id Decomposition: $tree_desc
# Rules: Complete decomposition to micro-task level
# Format: P.TTT.SS.AA.MM - Task Description

## Tree Structure

$tree_id - $tree_desc
‚îú‚îÄ‚îÄ ${tree_id%.000}.001 - [First Major Task]
‚îÇ   ‚îú‚îÄ‚îÄ ${tree_id%.000}.001.01 - [First Subtask]
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ${tree_id%.000}.001.01.01 - [First Atomic Task] (‚â§30 min)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ${tree_id%.000}.001.01.01.01 - [First Micro Task] (‚â§10 min)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ${tree_id%.000}.001.01.01.02 - [Second Micro Task] (‚â§10 min)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ${tree_id%.000}.001.01.01.03 - [Third Micro Task] (‚â§10 min)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ${tree_id%.000}.001.01.02 - [Second Atomic Task] (‚â§30 min)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ${tree_id%.000}.001.01.03 - [Third Atomic Task] (‚â§30 min)
‚îÇ   ‚îú‚îÄ‚îÄ ${tree_id%.000}.001.02 - [Second Subtask]
‚îÇ   ‚îî‚îÄ‚îÄ ${tree_id%.000}.001.03 - [Third Subtask]
‚îú‚îÄ‚îÄ ${tree_id%.000}.002 - [Second Major Task]
‚îî‚îÄ‚îÄ ${tree_id%.000}.003 - [Third Major Task]

## Detailed Task Definitions

### ${tree_id%.000}.001.01.01.01 - [Micro Task Name]
- **Objective**: Specific, measurable goal
- **Duration**: ‚â§10 minutes
- **Dependencies**: Prerequisites for this task
- **Success Criteria**: How to verify completion
- **Files Affected**: Specific file paths
- **Testing**: Validation steps required

[Continue for all tasks...]

## Tree Completion Checklist
- [ ] All major tasks identified
- [ ] All subtasks decomposed
- [ ] All atomic tasks ‚â§30 minutes
- [ ] All micro tasks ‚â§10 minutes
- [ ] Dependencies documented
- [ ] Success criteria defined
- [ ] Testing requirements specified
EOF
    
    # Open for editing
    if command -v nano >/dev/null 2>&1; then
        nano "$decomposition_file"
    elif command -v vim >/dev/null 2>&1; then
        vim "$decomposition_file"
    else
        log_error "No editor available. Please edit manually: $decomposition_file"
        return 1
    fi
    
    # Validate decomposition
    validate_tree_decomposition "$tree_id" "$decomposition_file"
    
    # Update planning state
    jq ".phases.phase_2_decomposition.trees_processed += [\"$tree_id\"] |
        .phases.phase_2_decomposition.current_tree = \"$tree_id\"" "$planning_state" > "$planning_state.tmp"
    mv "$planning_state.tmp" "$planning_state"
    
    # Check if all trees processed
    local total_trees
    total_trees=$(jq -r '.phases.phase_1_abstraction.tree_count' "$planning_state")
    local processed_count
    processed_count=$(jq -r '.phases.phase_2_decomposition.trees_processed | length' "$planning_state")
    
    if [ "$processed_count" -eq "$total_trees" ]; then
        jq '.phases.phase_2_decomposition.status = "completed" |
            .phases.phase_2_decomposition.completed_at = "$(date -Iseconds)" |
            .current_phase = "phase_3_second_pass"' "$planning_state" > "$planning_state.tmp"
        mv "$planning_state.tmp" "$planning_state"
        
        log_success "Phase 2 completed: All $total_trees trees decomposed"
        echo ""
        echo "Next step: $0 plan second-pass"
    else
        log_success "Tree $tree_id decomposed ($processed_count/$total_trees trees completed)"
        echo ""
        echo "Continue with next tree or run: $0 plan second-pass when all trees done"
    fi
}

# Validate tree decomposition
validate_tree_decomposition() {
    local tree_id="$1"
    local decomposition_file="$2"
    
    log_debug "Validating decomposition for tree $tree_id"
    
    # Count different task levels
    local atomic_tasks
    atomic_tasks=$(grep -E '^‚îÇ.*[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+\s' "$decomposition_file" | wc -l)
    local micro_tasks
    micro_tasks=$(grep -E '^‚îÇ.*[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+\s' "$decomposition_file" | wc -l)
    
    if [ "$atomic_tasks" -eq 0 ]; then
        log_warning "No atomic tasks found in decomposition"
    fi
    
    log_info "Decomposition stats: $atomic_tasks atomic tasks, $micro_tasks micro tasks"
}

# Execute second pass gap analysis
second_pass_analysis() {
    print_section "Phase 3: Second Pass Gap Analysis"
    
    local planning_state="$PLANNING_DIR/planning-state.json"
    local second_pass_file="$PLANNING_DIR/phase-3-second-pass/gap-analysis.md"
    
    # Check prerequisites
    local phase2_status
    phase2_status=$(jq -r '.phases.phase_2_decomposition.status' "$planning_state")
    
    if [ "$phase2_status" != "completed" ]; then
        log_error "Phase 2 decomposition must be completed first"
        exit 1
    fi
    
    mkdir -p "$(dirname "$second_pass_file")"
    
    # Create gap analysis template
    cat > "$second_pass_file" << 'EOF'
# Phase 3: Second Pass Gap Analysis
# Rules: Re-process entire decomposed list using identical methodology

## Gap Analysis Methodology

### 1. Dependency Review
- What dependencies were missed between tasks?
- Are there hidden prerequisites not captured?
- Do task dependencies create logical flow?

### 2. Integration Point Analysis  
- What integration tasks are needed between components?
- Are there communication/handoff tasks missing?
- Do different areas of work integrate properly?

### 3. Quality Gate Review
- What validation tasks are missing?
- Are there testing gaps between task levels?
- Do we have proper verification for each completion?

### 4. Edge Case Analysis
- What error handling tasks are needed?
- Are there failure recovery tasks missing?
- What happens when things go wrong?

### 5. Cross-Cutting Concerns
- Are there logging/monitoring tasks missing?
- Do we have proper documentation tasks?
- Are security considerations captured?

## Identified Gaps

### Missing Tasks
[List new tasks identified during second pass]

### Missing Dependencies
[List dependency relationships not captured]

### Missing Integration Points
[List integration tasks needed]

### Missing Quality Gates
[List validation/testing gaps]

## Updated Task Count
- Original atomic tasks: [COUNT]
- Original micro tasks: [COUNT]
- New tasks identified: [COUNT]
- Total tasks after second pass: [COUNT]

## Completion Checklist
- [ ] All decomposed trees re-reviewed
- [ ] Dependencies validated and gaps filled
- [ ] Integration points identified and tasked
- [ ] Quality gates verified complete
- [ ] Edge cases and error handling covered
- [ ] Cross-cutting concerns addressed
EOF
    
    log_info "Opening gap analysis template for editing..."
    
    # Open for editing
    if command -v nano >/dev/null 2>&1; then
        nano "$second_pass_file"
    elif command -v vim >/dev/null 2>&1; then
        vim "$second_pass_file"
    else
        log_error "No editor available. Please edit manually: $second_pass_file"
        return 1
    fi
    
    # Update planning state
    jq '.phases.phase_3_second_pass.status = "completed" |
        .phases.phase_3_second_pass.completed_at = "$(date -Iseconds)" |
        .current_phase = "planning_complete"' "$planning_state" > "$planning_state.tmp"
    mv "$planning_state.tmp" "$planning_state"
    
    log_success "Phase 3 second pass analysis completed"
    echo ""
    echo "üéØ Ultrathink Planning Protocol Complete!"
    echo "Next step: Create actual tasks with $0 task create"
}

# Show planning validation
validate_planning() {
    print_section "Planning Validation"
    
    local planning_state="$PLANNING_DIR/planning-state.json"
    
    if [ ! -f "$planning_state" ]; then
        log_error "No planning state found. Run: $0 plan start"
        exit 1
    fi
    
    local current_phase
    current_phase=$(jq -r '.current_phase' "$planning_state")
    
    echo "üìä Planning Status: $current_phase"
    echo ""
    
    # Phase 1 status
    local phase1_status
    phase1_status=$(jq -r '.phases.phase_1_abstraction.status' "$planning_state")
    local tree_count
    tree_count=$(jq -r '.phases.phase_1_abstraction.tree_count' "$planning_state")
    
    if [ "$phase1_status" = "completed" ]; then
        echo "‚úÖ Phase 1: Abstraction ($tree_count trees identified)"
    else
        echo "‚è≥ Phase 1: Abstraction (not completed)"
    fi
    
    # Phase 2 status
    local phase2_status
    phase2_status=$(jq -r '.phases.phase_2_decomposition.status' "$planning_state")
    local processed_count
    processed_count=$(jq -r '.phases.phase_2_decomposition.trees_processed | length' "$planning_state")
    
    if [ "$phase2_status" = "completed" ]; then
        echo "‚úÖ Phase 2: Decomposition ($processed_count/$tree_count trees processed)"
    else
        echo "‚è≥ Phase 2: Decomposition ($processed_count/$tree_count trees processed)"
    fi
    
    # Phase 3 status
    local phase3_status
    phase3_status=$(jq -r '.phases.phase_3_second_pass.status' "$planning_state")
    
    if [ "$phase3_status" = "completed" ]; then
        echo "‚úÖ Phase 3: Second Pass Gap Analysis"
    else
        echo "‚è≥ Phase 3: Second Pass Gap Analysis (not completed)"
    fi
    
    echo ""
    
    if [ "$current_phase" = "planning_complete" ]; then
        echo "üéØ Planning Complete - Ready for task execution"
        echo "Next step: $0 task create <task-id> <description>"
    else
        echo "‚ö†Ô∏è  Planning incomplete - continue with planning protocol"
    fi
}

# Show planning metrics
show_planning_metrics() {
    print_section "Planning Metrics"
    
    local planning_state="$PLANNING_DIR/planning-state.json"
    
    if [ ! -f "$planning_state" ]; then
        log_error "No planning state found"
        exit 1
    fi
    
    # Count tasks from decomposition files
    local total_atomic_tasks=0
    local total_micro_tasks=0
    
    for decomp_file in "$PLANNING_DIR/phase-2-decomposition"/*.md; do
        if [ -f "$decomp_file" ]; then
            local atomic_count
            atomic_count=$(grep -cE '[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+\s' "$decomp_file" || echo "0")
            local micro_count
            micro_count=$(grep -cE '[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+\s' "$decomp_file" || echo "0")
            
            total_atomic_tasks=$((total_atomic_tasks + atomic_count))
            total_micro_tasks=$((total_micro_tasks + micro_count))
        fi
    done
    
    local total_tasks=$((total_atomic_tasks + total_micro_tasks))
    
    echo "üìä Task Decomposition Metrics:"
    echo "  üå≥ Task Trees: $(jq -r '.phases.phase_1_abstraction.tree_count' "$planning_state")"
    echo "  ‚öõÔ∏è  Atomic Tasks: $total_atomic_tasks"
    echo "  üî¨ Micro Tasks: $total_micro_tasks"
    echo "  üìã Total Tasks: $total_tasks"
    echo ""
    echo "üéØ Planning Protocol Status:"
    echo "  Current Phase: $(jq -r '.current_phase' "$planning_state")"
    echo "  Started: $(jq -r '.planning_started_at' "$planning_state")"
    
    if [ "$total_tasks" -gt 0 ]; then
        echo ""
        echo "üí° Based on your task decomposition:"
        echo "  Estimated effort: $((total_tasks * 15)) - $((total_tasks * 30)) minutes"
        echo "  Estimated duration: $((total_tasks / 20)) - $((total_tasks / 10)) days (assuming 5-10 tasks/day)"
    fi
}

# Create new task with workspace and metadata
create_task() {
    local task_id="$1"
    local description="$2"
    
    if [ -z "$task_id" ] || [ -z "$description" ]; then
        log_error "Task ID and description required. Example: $0 task create 1.001.01.01 'Setup database'"
        exit 1
    fi
    
    print_section "Creating Task: $task_id"
    
    # Validate task ID format
    if ! [[ "$task_id" =~ ^[0-9]+\.[0-9]+(\.[0-9]+)*$ ]]; then
        log_error "Invalid task ID format. Use P.TTT.SS.AA.MM format"
        exit 1
    fi
    
    local task_dir="$ACTIVE_DIR/$task_id"
    
    if [ -d "$task_dir" ]; then
        log_error "Task $task_id already exists"
        exit 1
    fi
    
    # Create task workspace
    mkdir -p "$task_dir"/{workspace,evidence,artifacts,logs}
    
    # Generate task metadata
    local task_file="$task_dir/task.json"
    local status_file="$task_dir/status.json"
    local dependencies_file="$task_dir/dependencies.json"
    
    # Create task.json
    jq -n \
        --arg task_id "$task_id" \
        --arg title "$description" \
        --arg description "$description" \
        --arg created_at "$(date -Iseconds)" \
        '{ 
            task_id: $task_id,
            title: $title,
            description: $description,
            objective: "",
            success_criteria: [],
            duration_estimate_minutes: 30,
            complexity: "atomic",
            files_affected: [],
            testing_requirements: [],
            created_at: $created_at,
            created_by: "tony-framework",
            parent_task: null,
            child_tasks: [],
            tags: [],
            notes: ""
        }' > "$task_file"
    
    # Create status.json
    jq -n \
        --arg task_id "$task_id" \
        --arg last_updated "$(date -Iseconds)" \
        --arg workspace_path "$task_dir/workspace" \
        '{
            task_id: $task_id,
            status: "pending",
            assigned_agent: null,
            progress_percentage: 0,
            time_spent_minutes: 0,
            started_at: null,
            last_updated: $last_updated,
            completion_claimed_at: null,
            validated_at: null,
            blocked: false,
            blocking_reason: null,
            attempts: 0,
            failure_count: 0,
            last_failure_reason: null,
            workspace_path: $workspace_path,
            evidence_submitted: false,
            validation_passed: false
        }' > "$status_file"
    
    # Create dependencies.json
    jq -n \
        --arg task_id "$task_id" \
        --arg last_dependency_check "$(date -Iseconds)" \
        '{
            task_id: $task_id,
            prerequisites: [],
            blocks: [],
            related_tasks: [],
            external_dependencies: [],
            dependency_status: "ready",
            waiting_for: [],
            last_dependency_check: $last_dependency_check
        }' > "$dependencies_file"
    
    log_success "Task $task_id created successfully"
    echo "üìÅ Workspace: $task_dir"
    echo "Next steps: Add objectives and success criteria to $task_file"
}

# Show task status
show_task_status() {
    local task_id="$1"
    
    if [ -z "$task_id" ]; then
        # Show all tasks
        show_all_task_status
        return
    fi
    
    local task_dir="$ACTIVE_DIR/$task_id"
    
    if [ ! -d "$task_dir" ]; then
        # Check completed tasks
        task_dir="$COMPLETED_DIR/$task_id"
        if [ ! -d "$task_dir" ]; then
            log_error "Task $task_id not found"
            exit 1
        fi
    fi
    
    local task_file="$task_dir/task.json"
    local status_file="$task_dir/status.json"
    local dependencies_file="$task_dir/dependencies.json"
    
    print_section "Task Status: $task_id"
    
    # Basic info
    local title status assigned_agent progress
    title=$(jq -r '.title' "$task_file")
    status=$(jq -r '.status' "$status_file")
    assigned_agent=$(jq -r '.assigned_agent // "unassigned"' "$status_file")
    progress=$(jq -r '.progress_percentage' "$status_file")
    
    echo "üìã Title: $title"
    echo "üìä Status: $status ($progress% complete)"
    echo "üë§ Assigned: $assigned_agent"
    
    # Dependencies
    local prerequisites blocked
    prerequisites=$(jq -r '.prerequisites | length' "$dependencies_file")
    blocked=$(jq -r '.blocked' "$status_file")
    
    if [ "$blocked" = "true" ]; then
        local blocking_reason
        blocking_reason=$(jq -r '.blocking_reason' "$status_file")
        echo "üö´ Blocked: $blocking_reason"
    elif [ "$prerequisites" -gt 0 ]; then
        echo "‚è≥ Prerequisites: $prerequisites remaining"
    else
        echo "‚úÖ Ready for work"
    fi
    
    # Timing info
    local started_at time_spent
    started_at=$(jq -r '.started_at // "not started"' "$status_file")
    time_spent=$(jq -r '.time_spent_minutes' "$status_file")
    
    echo "‚è±Ô∏è  Started: $started_at"
    echo "‚è±Ô∏è  Time spent: ${time_spent} minutes"
    
    # Files and evidence
    local workspace_path evidence_submitted
    workspace_path=$(jq -r '.workspace_path' "$status_file")
    evidence_submitted=$(jq -r '.evidence_submitted' "$status_file")
    
    echo "üìÅ Workspace: $workspace_path"
    echo "üìã Evidence: $([ "$evidence_submitted" = "true" ] && echo "‚úÖ Submitted" || echo "‚ùå Pending")"
}

# Show all task status
show_all_task_status() {
    print_section "All Tasks Status"
    
    local total_tasks=0
    local completed_tasks=0
    local in_progress_tasks=0
    local pending_tasks=0
    local failed_tasks=0
    
    echo "üîÑ Active Tasks:"
    if [ -d "$ACTIVE_DIR" ] && [ "$(ls -A "$ACTIVE_DIR" 2>/dev/null)" ]; then
        for task_dir in "$ACTIVE_DIR"/*; do
            if [ -d "$task_dir" ]; then
                local task_id status
                task_id=$(basename "$task_dir")
                status=$(jq -r '.status' "$task_dir/status.json" 2>/dev/null || echo "unknown")
                
                case "$status" in
                    "completed") echo "  ‚úÖ $task_id"; ((completed_tasks++)) ;;
                    "in_progress") echo "  üîÑ $task_id"; ((in_progress_tasks++)) ;;
                    "failed") echo "  ‚ùå $task_id"; ((failed_tasks++)) ;;
                    *) echo "  ‚è≥ $task_id"; ((pending_tasks++)) ;;
                esac
                ((total_tasks++))
            fi
        done
    else
        echo "  No active tasks"
    fi
    
    echo ""
    echo "‚úÖ Completed Tasks:"
    if [ -d "$COMPLETED_DIR" ] && [ "$(ls -A "$COMPLETED_DIR" 2>/dev/null)" ]; then
        for task_dir in "$COMPLETED_DIR"/*; do
            if [ -d "$task_dir" ]; then
                local task_id
                task_id=$(basename "$task_dir")
                echo "  ‚úÖ $task_id"
                ((completed_tasks++))
                ((total_tasks++))
            fi
        done
    else
        echo "  No completed tasks"
    fi
    
    echo ""
    echo "üìä Summary:"
    echo "  üìã Total: $total_tasks"
    echo "  ‚úÖ Completed: $completed_tasks"
    echo "  üîÑ In Progress: $in_progress_tasks"
    echo "  ‚è≥ Pending: $pending_tasks"
    echo "  ‚ùå Failed: $failed_tasks"
}

# Assign task to agent
assign_task() {
    local task_id="$1"
    local agent_name="$2"
    
    if [ -z "$task_id" ] || [ -z "$agent_name" ]; then
        log_error "Task ID and agent name required. Example: $0 task assign 1.001.01.01 database-agent"
        exit 1
    fi
    
    local task_dir="$ACTIVE_DIR/$task_id"
    local status_file="$task_dir/status.json"
    
    if [ ! -f "$status_file" ]; then
        log_error "Task $task_id not found"
        exit 1
    fi
    
    # Check if task is available for assignment
    local current_status current_agent
    current_status=$(jq -r '.status' "$status_file")
    current_agent=$(jq -r '.assigned_agent // "null"' "$status_file")
    
    if [ "$current_agent" != "null" ] && [ "$current_agent" != "$agent_name" ]; then
        log_error "Task $task_id already assigned to $current_agent"
        exit 1
    fi
    
    # Update assignment
    jq --arg agent "$agent_name" \
       --arg updated "$(date -Iseconds)" \
       '.assigned_agent = $agent | .last_updated = $updated' \
       "$status_file" > "$status_file.tmp"
    mv "$status_file.tmp" "$status_file"
    
    log_success "Task $task_id assigned to $agent_name"
}

# Claim task ownership
claim_task() {
    local task_id="$1"
    
    if [ -z "$task_id" ]; then
        log_error "Task ID required. Example: $0 task claim 1.001.01.01"
        exit 1
    fi
    
    local task_dir="$ACTIVE_DIR/$task_id"
    local status_file="$task_dir/status.json"
    
    if [ ! -f "$status_file" ]; then
        log_error "Task $task_id not found"
        exit 1
    fi
    
    # Update status to in_progress and set start time
    jq --arg started "$(date -Iseconds)" \
       --arg updated "$(date -Iseconds)" \
       '.status = "in_progress" | .started_at = $started | .last_updated = $updated | .attempts += 1' \
       "$status_file" > "$status_file.tmp"
    mv "$status_file.tmp" "$status_file"
    
    local assigned_agent
    assigned_agent=$(jq -r '.assigned_agent // "unspecified-agent"' "$status_file")
    
    log_success "Task $task_id claimed by $assigned_agent"
    echo "üìÅ Workspace ready: $task_dir/workspace"
    echo "üìã Task details: $task_dir/task.json"
}

# Update task status
update_task_status() {
    local task_id="$1"
    local new_status="$2"
    
    if [ -z "$task_id" ] || [ -z "$new_status" ]; then
        log_error "Task ID and status required. Example: $0 task update 1.001.01.01 in_progress"
        exit 1
    fi
    
    local task_dir="$ACTIVE_DIR/$task_id"
    local status_file="$task_dir/status.json"
    
    if [ ! -f "$status_file" ]; then
        log_error "Task $task_id not found"
        exit 1
    fi
    
    # Validate status
    case "$new_status" in
        "pending"|"in_progress"|"completed"|"failed"|"blocked")
            ;;
        *)
            log_error "Invalid status: $new_status. Valid: pending, in_progress, completed, failed, blocked"
            exit 1
            ;;
    esac
    
    jq --arg status "$new_status" \
       --arg updated "$(date -Iseconds)" \
       '.status = $status | .last_updated = $updated' \
       "$status_file" > "$status_file.tmp"
    mv "$status_file.tmp" "$status_file"
    
    log_success "Task $task_id status updated to: $new_status"
}

# Complete task with evidence submission
complete_task() {
    local task_id="$1"
    
    if [ -z "$task_id" ]; then
        log_error "Task ID required. Example: $0 task complete 1.001.01.01"
        exit 1
    fi
    
    local task_dir="$ACTIVE_DIR/$task_id"
    local status_file="$task_dir/status.json"
    local evidence_dir="$task_dir/evidence"
    
    if [ ! -f "$status_file" ]; then
        log_error "Task $task_id not found"
        exit 1
    fi
    
    print_section "Completing Task: $task_id"
    
    # Check for evidence
    mkdir -p "$evidence_dir"
    
    echo "üìã Evidence Required for Task Completion"
    echo "Please provide evidence of completion in: $evidence_dir"
    echo ""
    echo "Evidence types:"
    echo "  - Code changes (screenshots, diffs)"
    echo "  - Test results (logs, coverage reports)"
    echo "  - Documentation updates"
    echo "  - Validation artifacts"
    echo ""
    
    if [ "$AUTO_CONFIRM" != true ]; then
        read -p "Have you added evidence to the evidence directory? (y/N): " evidence_confirm
        if [[ ! "$evidence_confirm" =~ ^[Yy]$ ]]; then
            log_info "Task completion cancelled. Add evidence and try again."
            exit 0
        fi
    fi
    
    # Update status
    jq --arg completed "$(date -Iseconds)" \
       --arg updated "$(date -Iseconds)" \
       '.status = "completed" | .completion_claimed_at = $completed | .last_updated = $updated | .evidence_submitted = true | .progress_percentage = 100' \
       "$status_file" > "$status_file.tmp"
    mv "$status_file.tmp" "$status_file"
    
    log_success "Task $task_id marked as completed"
    echo "üìã Evidence submitted for validation"
    echo "Next step: $0 task validate $task_id"
}

# Run automated validation checks (build, test, quality gates)
run_automated_validation() {
    local task_dir="$1"
    local workspace_dir="$task_dir/workspace"
    local evidence_dir="$task_dir/evidence"
    local validation_log="$task_dir/automated-validation.log"
    
    echo "ü§ñ Running automated validation checks..." > "$validation_log"
    local validation_passed=true
    
    # Change to workspace directory for validation
    local original_dir
    original_dir=$(pwd)
    
    if [ -d "$workspace_dir" ]; then
        cd "$workspace_dir" || return 1
    else
        echo "No workspace directory found, running from evidence directory" >> "$validation_log"
        cd "$evidence_dir" || return 1
    fi
    
    # 1. Project Detection and Build Validation
    if [ -f "package.json" ]; then
        echo "üì¶ Node.js project detected" >> "$validation_log"
        
        # Check for dependencies
        if [ -f "package-lock.json" ] || [ -d "node_modules" ]; then
            echo "‚úÖ Dependencies resolved" >> "$validation_log"
        else
            echo "‚ö†Ô∏è  No dependencies found - running npm install" >> "$validation_log"
            if npm install >> "$validation_log" 2>&1; then
                echo "‚úÖ Dependencies installed successfully" >> "$validation_log"
            else
                echo "‚ùå Dependency installation failed" >> "$validation_log"
                validation_passed=false
            fi
        fi
        
        # Run build if script exists
        if jq -e '.scripts.build' package.json > /dev/null 2>&1; then
            echo "üî® Running build..." >> "$validation_log"
            if npm run build >> "$validation_log" 2>&1; then
                echo "‚úÖ Build successful" >> "$validation_log"
            else
                echo "‚ùå Build failed" >> "$validation_log"
                validation_passed=false
            fi
        fi
        
        # Run tests if available
        if jq -e '.scripts.test' package.json > /dev/null 2>&1; then
            echo "üß™ Running tests..." >> "$validation_log"
            if npm test >> "$validation_log" 2>&1; then
                echo "‚úÖ Tests passed" >> "$validation_log"
            else
                echo "‚ùå Tests failed" >> "$validation_log"
                validation_passed=false
            fi
        fi
        
        # Check for linting
        if jq -e '.scripts.lint' package.json > /dev/null 2>&1; then
            echo "üîç Running linter..." >> "$validation_log"
            if npm run lint >> "$validation_log" 2>&1; then
                echo "‚úÖ Linting passed" >> "$validation_log"
            else
                echo "‚ö†Ô∏è  Linting issues found" >> "$validation_log"
            fi
        fi
        
    elif [ -f "requirements.txt" ] || [ -f "pyproject.toml" ]; then
        echo "üêç Python project detected" >> "$validation_log"
        
        # Check for virtual environment or install dependencies
        if [ -d "venv" ] || [ -d ".venv" ] || [ -n "$VIRTUAL_ENV" ]; then
            echo "‚úÖ Virtual environment detected" >> "$validation_log"
        else
            echo "‚ö†Ô∏è  No virtual environment found" >> "$validation_log"
        fi
        
        # Install dependencies if requirements.txt exists
        if [ -f "requirements.txt" ]; then
            echo "üì¶ Installing Python dependencies..." >> "$validation_log"
            if pip install -r requirements.txt >> "$validation_log" 2>&1; then
                echo "‚úÖ Dependencies installed" >> "$validation_log"
            else
                echo "‚ùå Dependency installation failed" >> "$validation_log"
                validation_passed=false
            fi
        fi
        
        # Run tests if pytest is available
        if command -v pytest >/dev/null 2>&1 && [ -d "tests" ]; then
            echo "üß™ Running pytest..." >> "$validation_log"
            if pytest >> "$validation_log" 2>&1; then
                echo "‚úÖ Tests passed" >> "$validation_log"
            else
                echo "‚ùå Tests failed" >> "$validation_log"
                validation_passed=false
            fi
        fi
        
        # Check for code quality with flake8 if available
        if command -v flake8 >/dev/null 2>&1; then
            echo "üîç Running flake8..." >> "$validation_log"
            if flake8 . >> "$validation_log" 2>&1; then
                echo "‚úÖ Code quality checks passed" >> "$validation_log"
            else
                echo "‚ö†Ô∏è  Code quality issues found" >> "$validation_log"
            fi
        fi
        
    elif [ -f "go.mod" ]; then
        echo "üî∑ Go project detected" >> "$validation_log"
        
        # Run go mod tidy
        echo "üì¶ Tidying Go modules..." >> "$validation_log"
        if go mod tidy >> "$validation_log" 2>&1; then
            echo "‚úÖ Go modules tidied" >> "$validation_log"
        else
            echo "‚ùå Go mod tidy failed" >> "$validation_log"
            validation_passed=false
        fi
        
        # Build the project
        echo "üî® Building Go project..." >> "$validation_log"
        if go build ./... >> "$validation_log" 2>&1; then
            echo "‚úÖ Build successful" >> "$validation_log"
        else
            echo "‚ùå Build failed" >> "$validation_log"
            validation_passed=false
        fi
        
        # Run tests
        echo "üß™ Running Go tests..." >> "$validation_log"
        if go test ./... >> "$validation_log" 2>&1; then
            echo "‚úÖ Tests passed" >> "$validation_log"
        else
            echo "‚ùå Tests failed" >> "$validation_log"
            validation_passed=false
        fi
        
    elif [ -f "Cargo.toml" ]; then
        echo "ü¶Ä Rust project detected" >> "$validation_log"
        
        # Check and build
        echo "üî® Building Rust project..." >> "$validation_log"
        if cargo check >> "$validation_log" 2>&1; then
            echo "‚úÖ Cargo check passed" >> "$validation_log"
            
            if cargo build >> "$validation_log" 2>&1; then
                echo "‚úÖ Build successful" >> "$validation_log"
            else
                echo "‚ùå Build failed" >> "$validation_log"
                validation_passed=false
            fi
        else
            echo "‚ùå Cargo check failed" >> "$validation_log"
            validation_passed=false
        fi
        
        # Run tests
        echo "üß™ Running Rust tests..." >> "$validation_log"
        if cargo test >> "$validation_log" 2>&1; then
            echo "‚úÖ Tests passed" >> "$validation_log"
        else
            echo "‚ùå Tests failed" >> "$validation_log"
            validation_passed=false
        fi
        
    else
        echo "‚ùì Generic project - running basic validations" >> "$validation_log"
        
        # Check for common build files
        if [ -f "Makefile" ]; then
            echo "üî® Running make..." >> "$validation_log"
            if make >> "$validation_log" 2>&1; then
                echo "‚úÖ Make successful" >> "$validation_log"
            else
                echo "‚ùå Make failed" >> "$validation_log"
                validation_passed=false
            fi
        fi
        
        # Check for shell scripts and validate syntax
        if ls *.sh 2>/dev/null | head -1 > /dev/null; then
            echo "üîç Validating shell scripts..." >> "$validation_log"
            for script in *.sh; do
                if bash -n "$script" >> "$validation_log" 2>&1; then
                    echo "‚úÖ $script syntax valid" >> "$validation_log"
                else
                    echo "‚ùå $script syntax error" >> "$validation_log"
                    validation_passed=false
                fi
            done
        fi
    fi
    
    # Generic quality checks
    echo "üîç Running generic quality checks..." >> "$validation_log"
    
    # Check for TODO/FIXME comments (warning only)
    if grep -r "TODO\|FIXME\|XXX" . 2>/dev/null | head -5 > /dev/null; then
        echo "‚ö†Ô∏è  TODO/FIXME comments found - consider addressing" >> "$validation_log"
    fi
    
    # Check for large files (>10MB)
    if find . -type f -size +10M 2>/dev/null | head -1 > /dev/null; then
        echo "‚ö†Ô∏è  Large files (>10MB) found - consider if necessary" >> "$validation_log"
    fi
    
    # Return to original directory
    cd "$original_dir" || return 1
    
    # Copy validation log to evidence
    cp "$validation_log" "$evidence_dir/automated-validation.log" 2>/dev/null || true
    
    if [ "$validation_passed" = true ]; then
        echo "‚úÖ Automated validation completed successfully" >> "$validation_log"
        return 0
    else
        echo "‚ùå Automated validation failed - check log for details" >> "$validation_log"
        return 1
    fi
}

# Validate task completion with comprehensive evidence analysis
validate_task() {
    local task_id="$1"
    
    if [ -z "$task_id" ]; then
        log_error "Task ID required. Example: $0 task validate 1.001.01.01"
        exit 1
    fi
    
    local task_dir="$ACTIVE_DIR/$task_id"
    local status_file="$task_dir/status.json"
    local task_file="$task_dir/task.json"
    local evidence_dir="$task_dir/evidence"
    local validation_report="$task_dir/validation-report.json"
    
    if [ ! -f "$status_file" ]; then
        log_error "Task $task_id not found"
        exit 1
    fi
    
    print_section "Evidence-Based Validation: $task_id"
    
    # Check if task is claimed as completed
    local status evidence_submitted
    status=$(jq -r '.status' "$status_file")
    evidence_submitted=$(jq -r '.evidence_submitted' "$status_file")
    
    if [ "$status" != "completed" ]; then
        log_error "Task $task_id is not marked as completed (status: $status)"
        exit 1
    fi
    
    if [ "$evidence_submitted" != "true" ]; then
        log_error "No evidence submitted for task $task_id"
        exit 1
    fi
    
    # Check evidence exists
    if [ ! -d "$evidence_dir" ] || [ -z "$(ls -A "$evidence_dir" 2>/dev/null)" ]; then
        log_error "No evidence found in $evidence_dir"
        exit 1
    fi
    
    # Initialize validation report
    local validation_score=0
    local max_score=100
    local validation_results=()
    
    # Automated Evidence Analysis
    echo "üîç Automated Evidence Analysis:"
    
    # 1. Code Evidence Validation (30 points)
    local code_score=0
    if ls "$evidence_dir"/*.{py,js,ts,go,rs,java,php,c,cpp,h} 2>/dev/null | head -1 > /dev/null; then
        echo "  ‚úÖ Code files found"
        code_score=15
        
        # Check for proper structure
        if grep -r "function\|class\|def\|fn\|func" "$evidence_dir"/ 2>/dev/null | head -1 > /dev/null; then
            echo "  ‚úÖ Structured code detected"
            code_score=$((code_score + 15))
        else
            echo "  ‚ö†Ô∏è  No structured code patterns found"
        fi
    else
        echo "  ‚ùå No code files found"
    fi
    validation_score=$((validation_score + code_score))
    
    # 2. Test Evidence Validation (25 points) 
    local test_score=0
    if ls "$evidence_dir"/*test* "$evidence_dir"/*spec* 2>/dev/null | head -1 > /dev/null; then
        echo "  ‚úÖ Test files found"
        test_score=15
        
        # Check for test execution results
        if ls "$evidence_dir"/test-results* "$evidence_dir"/coverage* 2>/dev/null | head -1 > /dev/null; then
            echo "  ‚úÖ Test execution results found"
            test_score=$((test_score + 10))
        else
            echo "  ‚ö†Ô∏è  No test execution results found"
        fi
    else
        echo "  ‚ùå No test files found"
    fi
    validation_score=$((validation_score + test_score))
    
    # 3. Documentation Evidence (20 points)
    local doc_score=0
    if ls "$evidence_dir"/*.md "$evidence_dir"/*.txt "$evidence_dir"/*.rst 2>/dev/null | head -1 > /dev/null; then
        echo "  ‚úÖ Documentation found"
        doc_score=10
        
        # Check for comprehensive documentation
        if grep -r "## \|### \|#### " "$evidence_dir"/ 2>/dev/null | head -1 > /dev/null; then
            echo "  ‚úÖ Structured documentation found"
            doc_score=$((doc_score + 10))
        else
            echo "  ‚ö†Ô∏è  Limited documentation structure"
        fi
    else
        echo "  ‚ùå No documentation found"
    fi
    validation_score=$((validation_score + doc_score))
    
    # 4. Build/Integration Evidence (25 points)
    local build_score=0
    if run_automated_validation "$task_dir"; then
        echo "  ‚úÖ Automated validation passed"
        build_score=25
    else
        echo "  ‚ùå Automated validation failed"
    fi
    validation_score=$((validation_score + build_score))
    
    # Display evidence inventory
    echo ""
    echo "üìã Evidence Inventory:"
    ls -la "$evidence_dir" | tail -n +2 | while read -r line; do
        echo "  $line"
    done
    
    # Success criteria verification
    local success_criteria
    success_criteria=$(jq -r '.success_criteria[]?' "$task_file" 2>/dev/null)
    
    if [ -n "$success_criteria" ]; then
        echo ""
        echo "‚úÖ Success Criteria Verification:"
        echo "$success_criteria" | while read -r criteria; do
            echo "  - $criteria"
        done
    fi
    
    # Generate validation report
    jq -n \
        --arg task_id "$task_id" \
        --arg validated_at "$(date -Iseconds)" \
        --arg evidence_score "$validation_score" \
        --arg max_score "$max_score" \
        --arg code_score "$code_score" \
        --arg test_score "$test_score" \
        --arg doc_score "$doc_score" \
        --arg build_score "$build_score" \
        '{
            task_id: $task_id,
            validated_at: $validated_at,
            validation_score: ($evidence_score | tonumber),
            max_score: ($max_score | tonumber),
            score_percentage: (($evidence_score | tonumber) / ($max_score | tonumber) * 100),
            component_scores: {
                code: ($code_score | tonumber),
                tests: ($test_score | tonumber),
                documentation: ($doc_score | tonumber),
                build_integration: ($build_score | tonumber)
            },
            validation_passed: false
        }' > "$validation_report"
    
    # Validation decision logic
    local score_percentage=$((validation_score * 100 / max_score))
    echo ""
    echo "üìä Validation Score: $validation_score/$max_score ($score_percentage%)"
    
    local validation_passed=false
    if [ "$score_percentage" -ge 80 ]; then
        echo "üéØ Validation Result: PASS (‚â•80% required)"
        validation_passed=true
    elif [ "$score_percentage" -ge 60 ]; then
        echo "‚ö†Ô∏è  Validation Result: CONDITIONAL PASS (manual review required)"
        if [ "$AUTO_CONFIRM" != true ]; then
            read -p "Accept conditional pass? Evidence may need improvement. (y/N): " conditional_confirm
            if [[ "$conditional_confirm" =~ ^[Yy]$ ]]; then
                validation_passed=true
            fi
        fi
    else
        echo "‚ùå Validation Result: FAIL (<60% - insufficient evidence)"
    fi
    
    # Final manual confirmation if needed
    if [ "$validation_passed" = true ] && [ "$AUTO_CONFIRM" != true ] && [ "$score_percentage" -lt 90 ]; then
        read -p "Confirm validation acceptance? (y/N): " final_confirm
        if [[ ! "$final_confirm" =~ ^[Yy]$ ]]; then
            validation_passed=false
        fi
    fi
    
    # Update validation report with final result
    jq --arg passed "$validation_passed" '.validation_passed = ($passed == "true")' "$validation_report" > "$validation_report.tmp"
    mv "$validation_report.tmp" "$validation_report"
    
    if [ "$validation_passed" = false ]; then
        log_error "Validation failed. Task $task_id requires additional work."
        
        # Reset to in_progress
        jq --arg updated "$(date -Iseconds)" \
           '.status = "in_progress" | .validation_passed = false | .last_updated = $updated | .evidence_submitted = false' \
           "$status_file" > "$status_file.tmp"
        mv "$status_file.tmp" "$status_file"
        exit 1
    fi
    
    # Mark as validated and move to completed
    jq --arg validated "$(date -Iseconds)" \
       --arg updated "$(date -Iseconds)" \
       --arg score "$validation_score" \
       '.validation_passed = true | .validated_at = $validated | .last_updated = $updated | .validation_score = ($score | tonumber)' \
       "$status_file" > "$status_file.tmp"
    mv "$status_file.tmp" "$status_file"
    
    # Move to completed directory
    mkdir -p "$COMPLETED_DIR"
    mv "$task_dir" "$COMPLETED_DIR/"
    
    log_success "Task $task_id validated and moved to completed (Score: $score_percentage%)"
    
    # Update dependencies - unblock dependent tasks
    update_dependent_tasks "$task_id"
}

# Update dependent tasks when a task completes
update_dependent_tasks() {
    local completed_task_id="$1"
    
    log_debug "Updating dependencies for completed task: $completed_task_id"
    
    # Find tasks that depend on this one
    for task_dir in "$ACTIVE_DIR"/*; do
        if [ -d "$task_dir" ]; then
            local dependencies_file="$task_dir/dependencies.json"
            if [ -f "$dependencies_file" ]; then
                # Check if this task has the completed task as a prerequisite
                local has_dependency
                has_dependency=$(jq --arg completed "$completed_task_id" '.prerequisites[] | select(. == $completed)' "$dependencies_file" 2>/dev/null)
                
                if [ -n "$has_dependency" ]; then
                    local dependent_task_id
                    dependent_task_id=$(basename "$task_dir")
                    
                    # Remove the completed task from prerequisites
                    jq --arg completed "$completed_task_id" \
                       --arg updated "$(date -Iseconds)" \
                       '.prerequisites = (.prerequisites - [$completed]) | .last_dependency_check = $updated' \
                       "$dependencies_file" > "$dependencies_file.tmp"
                    mv "$dependencies_file.tmp" "$dependencies_file"
                    
                    log_debug "Updated dependencies for task: $dependent_task_id"
                    
                    # Check if all prerequisites are now met
                    local remaining_prereqs
                    remaining_prereqs=$(jq -r '.prerequisites | length' "$dependencies_file")
                    
                    if [ "$remaining_prereqs" -eq 0 ]; then
                        # Unblock the task
                        local status_file="$task_dir/status.json"
                        jq --arg updated "$(date -Iseconds)" \
                           '.blocked = false | .blocking_reason = null | .dependency_status = "ready" | .last_updated = $updated' \
                           "$status_file" > "$status_file.tmp"
                        mv "$status_file.tmp" "$status_file"
                        
                        log_info "Task $dependent_task_id is now ready (dependencies resolved)"
                    fi
                fi
            fi
        fi
    done
}

# Recover failed or stuck tasks
recover_failed_tasks() {
    print_section "Task Recovery Analysis"
    
    local recovered_count=0
    local stuck_threshold_hours=24
    local current_time
    current_time=$(date +%s)
    
    echo "üîç Scanning for failed or stuck tasks..."
    
    for task_dir in "$ACTIVE_DIR"/*; do
        if [ -d "$task_dir" ]; then
            local task_id status_file
            task_id=$(basename "$task_dir")
            status_file="$task_dir/status.json"
            
            if [ -f "$status_file" ]; then
                local status started_at last_updated
                status=$(jq -r '.status' "$status_file")
                started_at=$(jq -r '.started_at // empty' "$status_file")
                last_updated=$(jq -r '.last_updated' "$status_file")
                
                # Check for failed tasks
                if [ "$status" = "failed" ]; then
                    echo "‚ùå Failed task detected: $task_id"
                    
                    # Reset to pending for retry
                    jq --arg updated "$(date -Iseconds)" \
                       '.status = "pending" | .assigned_agent = null | .started_at = null | .failure_count += 1 | .last_updated = $updated' \
                       "$status_file" > "$status_file.tmp"
                    mv "$status_file.tmp" "$status_file"
                    
                    echo "  üîÑ Reset to pending for retry"
                    ((recovered_count++))
                    
                # Check for stuck tasks (in progress for too long)
                elif [ "$status" = "in_progress" ] && [ -n "$started_at" ]; then
                    local started_timestamp
                    started_timestamp=$(date -d "$started_at" +%s 2>/dev/null || echo "0")
                    local hours_elapsed
                    hours_elapsed=$(( (current_time - started_timestamp) / 3600 ))
                    
                    if [ "$hours_elapsed" -gt "$stuck_threshold_hours" ]; then
                        echo "‚è∞ Stuck task detected: $task_id (${hours_elapsed}h elapsed)"
                        
                        # Reset to pending
                        jq --arg updated "$(date -Iseconds)" \
                           '.status = "pending" | .assigned_agent = null | .started_at = null | .last_updated = $updated' \
                           "$status_file" > "$status_file.tmp"
                        mv "$status_file.tmp" "$status_file"
                        
                        echo "  üîÑ Reset due to timeout"
                        ((recovered_count++))
                    fi
                fi
            fi
        fi
    done
    
    if [ "$recovered_count" -eq 0 ]; then
        log_success "No failed or stuck tasks found"
    else
        log_success "Recovered $recovered_count tasks"
    fi
    
    # Perform state integrity check after recovery
    validate_state_integrity
}

# Create comprehensive state backup
create_state_backup() {
    local backup_dir="$TASK_ROOT/backups"
    local timestamp
    timestamp=$(date +%Y%m%d-%H%M%S)
    local backup_path="$backup_dir/athms-backup-$timestamp"
    
    print_section "Creating ATHMS State Backup"
    
    mkdir -p "$backup_path"
    
    # Backup all task data
    if [ -d "$ACTIVE_DIR" ]; then
        cp -r "$ACTIVE_DIR" "$backup_path/" 2>/dev/null || true
        log_info "Active tasks backed up"
    fi
    
    if [ -d "$COMPLETED_DIR" ]; then
        cp -r "$COMPLETED_DIR" "$backup_path/" 2>/dev/null || true  
        log_info "Completed tasks backed up"
    fi
    
    if [ -d "$PLANNING_DIR" ]; then
        cp -r "$PLANNING_DIR" "$backup_path/" 2>/dev/null || true
        log_info "Planning data backed up"
    fi
    
    # Create backup manifest
    cat > "$backup_path/backup-manifest.json" << EOF
{
    "backup_timestamp": "$(date -Iseconds)",
    "backup_type": "full_state",
    "athms_version": "1.0.0",
    "total_active_tasks": $(find "$ACTIVE_DIR" -type d -mindepth 1 2>/dev/null | wc -l),
    "total_completed_tasks": $(find "$COMPLETED_DIR" -type d -mindepth 1 2>/dev/null | wc -l),
    "planning_phase": "$(jq -r '.current_phase // "not_started"' "$PLANNING_DIR/planning-state.json" 2>/dev/null)",
    "backup_size_mb": $(du -sm "$backup_path" 2>/dev/null | cut -f1)
}
EOF
    
    # Compress backup for storage efficiency
    if command -v tar >/dev/null 2>&1; then
        tar -czf "$backup_path.tar.gz" -C "$backup_dir" "$(basename "$backup_path")" 2>/dev/null && rm -rf "$backup_path"
        log_success "State backup created: $backup_path.tar.gz"
        
        # Cleanup old backups (keep last 10)
        ls -t "$backup_dir"/athms-backup-*.tar.gz 2>/dev/null | tail -n +11 | xargs rm -f 2>/dev/null || true
        
        echo "$backup_path.tar.gz"
    else
        log_success "State backup created: $backup_path"
        echo "$backup_path"
    fi
}

# Restore state from backup
restore_state_backup() {
    local backup_path="$1"
    
    if [ -z "$backup_path" ]; then
        log_error "Backup path required. Example: $0 restore /path/to/backup"
        exit 1
    fi
    
    if [ ! -f "$backup_path" ] && [ ! -d "$backup_path" ]; then
        log_error "Backup not found: $backup_path"
        exit 1
    fi
    
    print_section "Restoring ATHMS State from Backup"
    
    # Create current state backup before restore
    log_info "Creating safety backup of current state..."
    local safety_backup
    safety_backup=$(create_state_backup)
    
    # Extract backup if compressed
    local restore_dir
    if [[ "$backup_path" == *.tar.gz ]]; then
        restore_dir=$(mktemp -d)
        if tar -xzf "$backup_path" -C "$restore_dir" 2>/dev/null; then
            backup_path="$restore_dir/$(basename "$backup_path" .tar.gz)"
        else
            log_error "Failed to extract backup archive"
            rm -rf "$restore_dir"
            exit 1
        fi
    else
        restore_dir=""
    fi
    
    # Validate backup integrity
    if [ ! -f "$backup_path/backup-manifest.json" ]; then
        log_error "Invalid backup: missing manifest"
        [ -n "$restore_dir" ] && rm -rf "$restore_dir"
        exit 1
    fi
    
    # Stop any running processes that might interfere
    log_info "Stopping interfering processes..."
    
    # Clear existing state
    log_info "Clearing current state..."
    rm -rf "$ACTIVE_DIR" "$COMPLETED_DIR" "$PLANNING_DIR" 2>/dev/null || true
    
    # Restore from backup
    if [ -d "$backup_path/active" ]; then
        cp -r "$backup_path/active" "$ACTIVE_DIR"
        log_info "Active tasks restored"
    fi
    
    if [ -d "$backup_path/completed" ]; then
        cp -r "$backup_path/completed" "$COMPLETED_DIR"
        log_info "Completed tasks restored"
    fi
    
    if [ -d "$backup_path/planning" ]; then
        cp -r "$backup_path/planning" "$PLANNING_DIR"
        log_info "Planning data restored"
    fi
    
    # Validate restored state
    if validate_state_integrity --quiet; then
        log_success "State restored successfully from backup"
        log_info "Safety backup available at: $safety_backup"
    else
        log_error "State restoration failed validation - rolling back"
        restore_state_backup "$safety_backup"
    fi
    
    # Cleanup temporary extraction
    [ -n "$restore_dir" ] && rm -rf "$restore_dir"
}

# Validate and repair state integrity
validate_state_integrity() {
    local quiet_mode=false
    if [ "$1" = "--quiet" ]; then
        quiet_mode=true
    fi
    
    [ "$quiet_mode" = false ] && print_section "ATHMS State Integrity Validation"
    
    local issues_found=0
    local repairs_made=0
    
    # 1. Validate directory structure
    local required_dirs=("$TASK_ROOT" "$PLANNING_DIR" "$ACTIVE_DIR" "$COMPLETED_DIR" "$TEMPLATES_DIR")
    for dir in "${required_dirs[@]}"; do
        if [ ! -d "$dir" ]; then
            [ "$quiet_mode" = false ] && log_warning "Missing directory: $dir"
            mkdir -p "$dir"
            ((repairs_made++))
        fi
    done
    
    # 2. Validate task JSON integrity
    for task_dir in "$ACTIVE_DIR"/* "$COMPLETED_DIR"/*; do
        if [ -d "$task_dir" ]; then
            local task_id
            task_id=$(basename "$task_dir")
            
            # Validate required JSON files
            local json_files=("task.json" "status.json" "dependencies.json")
            for json_file in "${json_files[@]}"; do
                local file_path="$task_dir/$json_file"
                if [ ! -f "$file_path" ]; then
                    [ "$quiet_mode" = false ] && log_warning "Missing $json_file for task $task_id"
                    ((issues_found++))
                    
                    # Attempt repair with template
                    if [ -f "$TEMPLATES_DIR/$json_file" ]; then
                        cp "$TEMPLATES_DIR/$json_file" "$file_path"
                        # Update with task ID
                        jq --arg task_id "$task_id" '.task_id = $task_id' "$file_path" > "$file_path.tmp"
                        mv "$file_path.tmp" "$file_path"
                        ((repairs_made++))
                    fi
                elif ! jq empty "$file_path" 2>/dev/null; then
                    [ "$quiet_mode" = false ] && log_warning "Corrupted JSON in $json_file for task $task_id"
                    ((issues_found++))
                    
                    # Attempt repair from backup
                    if [ -f "$file_path.backup" ]; then
                        cp "$file_path.backup" "$file_path"
                        ((repairs_made++))
                    fi
                fi
            done
        fi
    done
    
    # 3. Validate dependency consistency
    for task_dir in "$ACTIVE_DIR"/*; do
        if [ -d "$task_dir" ]; then
            local task_id dependencies_file
            task_id=$(basename "$task_dir")
            dependencies_file="$task_dir/dependencies.json"
            
            if [ -f "$dependencies_file" ]; then
                # Check if prerequisite tasks exist
                local prerequisites
                prerequisites=$(jq -r '.prerequisites[]?' "$dependencies_file" 2>/dev/null)
                
                while IFS= read -r prereq; do
                    if [ -n "$prereq" ] && [ ! -d "$ACTIVE_DIR/$prereq" ] && [ ! -d "$COMPLETED_DIR/$prereq" ]; then
                        [ "$quiet_mode" = false ] && log_warning "Task $task_id references non-existent prerequisite: $prereq"
                        
                        # Remove invalid prerequisite
                        jq --arg prereq "$prereq" '.prerequisites = (.prerequisites - [$prereq])' "$dependencies_file" > "$dependencies_file.tmp"
                        mv "$dependencies_file.tmp" "$dependencies_file"
                        ((repairs_made++))
                    fi
                done <<< "$prerequisites"
            fi
        fi
    done
    
    # 4. Validate planning state consistency
    local planning_state="$PLANNING_DIR/planning-state.json"
    if [ -f "$planning_state" ]; then
        if ! jq empty "$planning_state" 2>/dev/null; then
            [ "$quiet_mode" = false ] && log_warning "Corrupted planning state"
            ((issues_found++))
            
            # Attempt repair by reinitializing
            init_planning_state
            ((repairs_made++))
        fi
    fi
    
    # 5. Create state snapshot for future recovery
    create_state_snapshot
    
    if [ "$quiet_mode" = false ]; then
        if [ "$issues_found" -eq 0 ]; then
            log_success "State integrity validation passed"
        else
            log_info "State integrity issues found: $issues_found, repairs made: $repairs_made"
        fi
    fi
    
    return $((issues_found > repairs_made ? 1 : 0))
}

# Create lightweight state snapshot
create_state_snapshot() {
    local snapshot_dir="$TASK_ROOT/snapshots"
    local timestamp
    timestamp=$(date +%Y%m%d-%H%M%S)
    local snapshot_file="$snapshot_dir/state-snapshot-$timestamp.json"
    
    mkdir -p "$snapshot_dir"
    
    # Create lightweight state snapshot
    jq -n \
        --arg timestamp "$(date -Iseconds)" \
        --arg planning_phase "$(jq -r '.current_phase // "not_started"' "$PLANNING_DIR/planning-state.json" 2>/dev/null)" \
        --arg active_tasks "$(find "$ACTIVE_DIR" -type d -mindepth 1 2>/dev/null | wc -l)" \
        --arg completed_tasks "$(find "$COMPLETED_DIR" -type d -mindepth 1 2>/dev/null | wc -l)" \
        '{
            snapshot_timestamp: $timestamp,
            planning_phase: $planning_phase,
            active_tasks_count: ($active_tasks | tonumber),
            completed_tasks_count: ($completed_tasks | tonumber),
            task_status_summary: {}
        }' > "$snapshot_file"
    
    # Add task status summary
    for task_dir in "$ACTIVE_DIR"/*; do
        if [ -d "$task_dir" ]; then
            local task_id status
            task_id=$(basename "$task_dir")
            status=$(jq -r '.status // "unknown"' "$task_dir/status.json" 2>/dev/null)
            
            jq --arg task_id "$task_id" --arg status "$status" \
               '.task_status_summary[$task_id] = $status' \
               "$snapshot_file" > "$snapshot_file.tmp"
            mv "$snapshot_file.tmp" "$snapshot_file"
        fi
    done
    
    # Cleanup old snapshots (keep last 20)
    ls -t "$snapshot_dir"/state-snapshot-*.json 2>/dev/null | tail -n +21 | xargs rm -f 2>/dev/null || true
    
    log_debug "State snapshot created: $snapshot_file"
}

# Emergency state recovery
emergency_recovery() {
    print_section "ATHMS Emergency State Recovery"
    
    log_warning "Initiating emergency recovery protocol..."
    
    # 1. Attempt automatic backup restoration
    local latest_backup
    latest_backup=$(ls -t "$TASK_ROOT/backups"/athms-backup-*.tar.gz 2>/dev/null | head -1)
    
    if [ -n "$latest_backup" ]; then
        log_info "Found recent backup: $latest_backup"
        read -p "Restore from backup? (y/N): " restore_confirm
        if [[ "$restore_confirm" =~ ^[Yy]$ ]]; then
            restore_state_backup "$latest_backup"
            return
        fi
    fi
    
    # 2. Attempt state reconstruction from snapshots
    local latest_snapshot
    latest_snapshot=$(ls -t "$TASK_ROOT/snapshots"/state-snapshot-*.json 2>/dev/null | head -1)
    
    if [ -n "$latest_snapshot" ]; then
        log_info "Found state snapshot: $latest_snapshot"
        log_info "Snapshot details:"
        jq -r '"  Planning Phase: " + .planning_phase + "\n  Active Tasks: " + (.active_tasks_count | tostring) + "\n  Completed Tasks: " + (.completed_tasks_count | tostring)' "$latest_snapshot"
        
        read -p "Attempt reconstruction from snapshot? (y/N): " reconstruct_confirm
        if [[ "$reconstruct_confirm" =~ ^[Yy]$ ]]; then
            reconstruct_from_snapshot "$latest_snapshot"
            return
        fi
    fi
    
    # 3. Clean slate initialization
    log_warning "No viable recovery options found"
    read -p "Initialize clean ATHMS state? This will lose all current data. (y/N): " clean_confirm
    if [[ "$clean_confirm" =~ ^[Yy]$ ]]; then
        rm -rf "$TASK_ROOT"
        init_athms
        log_success "Clean ATHMS state initialized"
    else
        log_error "Emergency recovery cancelled"
        exit 1
    fi
}

# Reconstruct state from snapshot (partial recovery)
reconstruct_from_snapshot() {
    local snapshot_file="$1"
    
    print_section "Reconstructing State from Snapshot"
    
    # Create basic directory structure
    init_athms
    
    # Extract task information from snapshot
    local task_count
    task_count=$(jq -r '.task_status_summary | keys | length' "$snapshot_file")
    
    if [ "$task_count" -gt 0 ]; then
        log_info "Reconstructing $task_count tasks from snapshot..."
        
        # Create placeholder tasks based on snapshot
        jq -r '.task_status_summary | to_entries[] | "\(.key) \(.value)"' "$snapshot_file" | while read -r task_id status; do
            if [ ! -d "$ACTIVE_DIR/$task_id" ] && [ ! -d "$COMPLETED_DIR/$task_id" ]; then
                local target_dir
                if [ "$status" = "completed" ]; then
                    target_dir="$COMPLETED_DIR/$task_id"
                else
                    target_dir="$ACTIVE_DIR/$task_id"
                fi
                
                # Create minimal task structure
                mkdir -p "$target_dir"/{workspace,evidence,artifacts,logs}
                
                # Create basic metadata (reconstructed)
                jq -n \
                    --arg task_id "$task_id" \
                    --arg status "$status" \
                    --arg timestamp "$(date -Iseconds)" \
                    '{
                        task_id: $task_id,
                        title: "Reconstructed task",
                        description: "Task reconstructed from state snapshot",
                        objective: "Original data lost - review and update",
                        success_criteria: ["Review task requirements", "Update task metadata"],
                        created_at: $timestamp,
                        created_by: "emergency-recovery",
                        notes: "‚ö†Ô∏è RECONSTRUCTED FROM SNAPSHOT - REVIEW REQUIRED"
                    }' > "$target_dir/task.json"
                
                jq -n \
                    --arg task_id "$task_id" \
                    --arg status "$status" \
                    --arg timestamp "$(date -Iseconds)" \
                    '{
                        task_id: $task_id,
                        status: $status,
                        last_updated: $timestamp,
                        workspace_path: "'"$target_dir/workspace"'",
                        reconstruction_note: "Task reconstructed from snapshot"
                    }' > "$target_dir/status.json"
                
                jq -n \
                    --arg task_id "$task_id" \
                    --arg timestamp "$(date -Iseconds)" \
                    '{
                        task_id: $task_id,
                        prerequisites: [],
                        blocks: [],
                        related_tasks: [],
                        external_dependencies: [],
                        dependency_status: "unknown",
                        waiting_for: [],
                        last_dependency_check: $timestamp
                    }' > "$target_dir/dependencies.json"
                
                log_debug "Reconstructed task: $task_id ($status)"
            fi
        done
    fi
    
    log_success "State reconstruction completed"
    log_warning "‚ö†Ô∏è  Reconstructed tasks require manual review and metadata updates"
    
    # Validate reconstructed state
    validate_state_integrity
}

# Generate comprehensive project report
generate_project_report() {
    print_section "ATHMS Project Progress Report"
    
    local report_dir="$TASK_ROOT/reports"
    local timestamp
    timestamp=$(date +%Y%m%d-%H%M%S)
    local report_file="$report_dir/project-report-$timestamp.md"
    
    mkdir -p "$report_dir"
    
    # Gather statistics
    local total_active=$(find "$ACTIVE_DIR" -type d -mindepth 1 2>/dev/null | wc -l)
    local total_completed=$(find "$COMPLETED_DIR" -type d -mindepth 1 2>/dev/null | wc -l)
    local total_tasks=$((total_active + total_completed))
    
    # Count by status
    local pending_count=0
    local in_progress_count=0
    local completed_count=$total_completed
    local failed_count=0
    
    for task_dir in "$ACTIVE_DIR"/*; do
        if [ -d "$task_dir" ]; then
            local status
            status=$(jq -r '.status // "pending"' "$task_dir/status.json" 2>/dev/null)
            case "$status" in
                "pending") ((pending_count++)) ;;
                "in_progress") ((in_progress_count++)) ;;
                "failed") ((failed_count++)) ;;
            esac
        fi
    done
    
    # Calculate percentages
    local completion_percentage=0
    if [ "$total_tasks" -gt 0 ]; then
        completion_percentage=$((completed_count * 100 / total_tasks))
    fi
    
    # Generate report
    cat > "$report_file" << EOF
# ATHMS Project Progress Report

**Generated**: $(date)  
**Project**: $(basename "$(pwd)")  
**Report Period**: Project lifetime  

## üìä Executive Summary

### Overall Progress
- **Total Tasks**: $total_tasks
- **Completion Rate**: $completion_percentage% ($completed_count/$total_tasks)
- **Active Tasks**: $total_active
- **Project Status**: $([ "$completion_percentage" -ge 90 ] && echo "Near Completion" || [ "$completion_percentage" -ge 50 ] && echo "In Progress" || echo "Early Stage")

### Task Breakdown
| Status | Count | Percentage |
|--------|-------|------------|
| ‚úÖ Completed | $completed_count | $((total_tasks > 0 ? completed_count * 100 / total_tasks : 0))% |
| üîÑ In Progress | $in_progress_count | $((total_tasks > 0 ? in_progress_count * 100 / total_tasks : 0))% |
| ‚è≥ Pending | $pending_count | $((total_tasks > 0 ? pending_count * 100 / total_tasks : 0))% |
| ‚ùå Failed | $failed_count | $((total_tasks > 0 ? failed_count * 100 / total_tasks : 0))% |

## üìã Planning Status

EOF

    # Add planning information
    local planning_state="$PLANNING_DIR/planning-state.json"
    if [ -f "$planning_state" ]; then
        local current_phase
        current_phase=$(jq -r '.current_phase // "not_started"' "$planning_state")
        
        cat >> "$report_file" << EOF
### Ultrathink Planning Protocol
- **Current Phase**: $current_phase
- **Planning Started**: $(jq -r '.planning_started_at // "Not started"' "$planning_state")

#### Phase Completion Status
EOF
        
        local phase1_status
        phase1_status=$(jq -r '.phases.phase_1_abstraction.status // "not_started"' "$planning_state")
        echo "- **Phase 1 (Abstraction)**: $phase1_status" >> "$report_file"
        
        local phase2_status
        phase2_status=$(jq -r '.phases.phase_2_decomposition.status // "not_started"' "$planning_state")
        echo "- **Phase 2 (Decomposition)**: $phase2_status" >> "$report_file"
        
        local phase3_status
        phase3_status=$(jq -r '.phases.phase_3_second_pass.status // "not_started"' "$planning_state")
        echo "- **Phase 3 (Second Pass)**: $phase3_status" >> "$report_file"
    else
        echo "### Planning Status: Not initialized" >> "$report_file"
    fi
    
    # Add active tasks details
    cat >> "$report_file" << EOF

## üîÑ Active Tasks Detail

EOF
    
    if [ "$total_active" -gt 0 ]; then
        for task_dir in "$ACTIVE_DIR"/*; do
            if [ -d "$task_dir" ]; then
                local task_id title status assigned_agent progress
                task_id=$(basename "$task_dir")
                title=$(jq -r '.title // "No title"' "$task_dir/task.json" 2>/dev/null)
                status=$(jq -r '.status // "pending"' "$task_dir/status.json" 2>/dev/null)
                assigned_agent=$(jq -r '.assigned_agent // "unassigned"' "$task_dir/status.json" 2>/dev/null)
                progress=$(jq -r '.progress_percentage // 0' "$task_dir/status.json" 2>/dev/null)
                
                cat >> "$report_file" << EOF
### $task_id - $title
- **Status**: $status ($progress% complete)
- **Assigned**: $assigned_agent
- **Workspace**: \`$task_dir/workspace\`

EOF
            fi
        done
    else
        echo "No active tasks found." >> "$report_file"
    fi
    
    # Add recent completions
    cat >> "$report_file" << EOF

## ‚úÖ Recent Completions

EOF
    
    if [ "$total_completed" -gt 0 ]; then
        # Get last 10 completed tasks by completion date
        find "$COMPLETED_DIR" -name "status.json" -exec grep -l "validated_at" {} \; 2>/dev/null | \
        head -10 | while read -r status_file; do
            local task_dir task_id title validated_at score
            task_dir=$(dirname "$status_file")
            task_id=$(basename "$task_dir")
            title=$(jq -r '.title // "No title"' "$task_dir/task.json" 2>/dev/null)
            validated_at=$(jq -r '.validated_at // "Unknown"' "$status_file" 2>/dev/null)
            score=$(jq -r '.validation_score // "N/A"' "$status_file" 2>/dev/null)
            
            echo "- **$task_id**: $title (Completed: $validated_at, Score: $score)" >> "$report_file"
        done
    else
        echo "No completed tasks found." >> "$report_file"
    fi
    
    # Add system health
    cat >> "$report_file" << EOF

## üîß System Health

### State Integrity
- **Last Validation**: $(date)
- **Backup Status**: $(ls -t "$TASK_ROOT/backups"/athms-backup-*.tar.gz 2>/dev/null | head -1 | xargs basename 2>/dev/null || echo "No backups found")
- **Snapshot Count**: $(ls "$TASK_ROOT/snapshots"/state-snapshot-*.json 2>/dev/null | wc -l)

### Storage Usage
- **Total Size**: $(du -sh "$TASK_ROOT" 2>/dev/null | cut -f1)
- **Active Tasks**: $(du -sh "$ACTIVE_DIR" 2>/dev/null | cut -f1)
- **Completed Tasks**: $(du -sh "$COMPLETED_DIR" 2>/dev/null | cut -f1)
- **Backups**: $(du -sh "$TASK_ROOT/backups" 2>/dev/null | cut -f1)

---

*Report generated by ATHMS v1.0.0*
EOF
    
    log_success "Project report generated: $report_file"
    
    # Display summary
    echo ""
    echo "üìä Report Summary:"
    echo "  Total Tasks: $total_tasks"
    echo "  Completion: $completion_percentage%"
    echo "  Active: $total_active tasks"
    echo "  Failed: $failed_count tasks"
    echo ""
    echo "üìÅ Full report: $report_file"
}

# Clean up completed tasks and old data
cleanup_completed_tasks() {
    print_section "ATHMS Cleanup Operations"
    
    local cleanup_performed=false
    
    # 1. Archive old completed tasks (older than 30 days)
    local archive_dir="$TASK_ROOT/archive"
    local cutoff_date
    cutoff_date=$(date -d "30 days ago" +%s)
    
    if [ -d "$COMPLETED_DIR" ]; then
        for task_dir in "$COMPLETED_DIR"/*; do
            if [ -d "$task_dir" ]; then
                local status_file="$task_dir/status.json"
                if [ -f "$status_file" ]; then
                    local validated_at
                    validated_at=$(jq -r '.validated_at // empty' "$status_file" 2>/dev/null)
                    
                    if [ -n "$validated_at" ]; then
                        local validated_timestamp
                        validated_timestamp=$(date -d "$validated_at" +%s 2>/dev/null || echo "0")
                        
                        if [ "$validated_timestamp" -lt "$cutoff_date" ]; then
                            local task_id
                            task_id=$(basename "$task_dir")
                            
                            mkdir -p "$archive_dir"
                            mv "$task_dir" "$archive_dir/"
                            log_info "Archived old completed task: $task_id"
                            cleanup_performed=true
                        fi
                    fi
                fi
            fi
        done
    fi
    
    # 2. Clean up old logs
    local logs_dir="$TASK_ROOT/logs"
    if [ -d "$logs_dir" ]; then
        find "$logs_dir" -name "*.log" -mtime +7 -delete 2>/dev/null || true
        log_info "Cleaned up old log files (>7 days)"
        cleanup_performed=true
    fi
    
    # 3. Clean up temporary files
    find "$TASK_ROOT" -name "*.tmp" -delete 2>/dev/null || true
    find "$TASK_ROOT" -name "*.backup" -mtime +7 -delete 2>/dev/null || true
    
    # 4. Compress old reports
    local reports_dir="$TASK_ROOT/reports"
    if [ -d "$reports_dir" ]; then
        find "$reports_dir" -name "*.md" -mtime +14 -exec gzip {} \; 2>/dev/null || true
        log_info "Compressed old reports (>14 days)"
        cleanup_performed=true
    fi
    
    # 5. Clean up orphaned evidence directories
    for evidence_dir in "$ACTIVE_DIR"/*/evidence "$COMPLETED_DIR"/*/evidence; do
        if [ -d "$evidence_dir" ]; then
            local task_dir
            task_dir=$(dirname "$evidence_dir")
            if [ ! -f "$task_dir/task.json" ]; then
                rm -rf "$evidence_dir"
                log_info "Cleaned up orphaned evidence directory: $evidence_dir"
                cleanup_performed=true
            fi
        fi
    done
    
    # 6. Optimize JSON files (remove formatting)
    for json_file in $(find "$TASK_ROOT" -name "*.json" -type f); do
        if [ -f "$json_file" ] && jq empty "$json_file" 2>/dev/null; then
            jq -c . "$json_file" > "$json_file.optimized" 2>/dev/null && mv "$json_file.optimized" "$json_file"
        fi
    done
    
    if [ "$cleanup_performed" = true ]; then
        log_success "Cleanup completed successfully"
        
        # Show space saved
        echo ""
        echo "üìä Current storage usage:"
        echo "  Total: $(du -sh "$TASK_ROOT" 2>/dev/null | cut -f1)"
        echo "  Active: $(du -sh "$ACTIVE_DIR" 2>/dev/null | cut -f1)"
        echo "  Completed: $(du -sh "$COMPLETED_DIR" 2>/dev/null | cut -f1)"
        echo "  Archive: $(du -sh "$archive_dir" 2>/dev/null | cut -f1)"
    else
        log_info "No cleanup operations needed"
    fi
}

# Agent-ATHMS Integration Bridge
integrate_agent_athms() {
    print_section "Implementing Agent-ATHMS Integration Bridge"
    
    local integration_dir="$TASK_ROOT/integration"
    mkdir -p "$integration_dir"/{agents,assignments,monitoring}
    
    # Create agent registry
    cat > "$integration_dir/agent-registry.json" << 'EOF'
{
  "agents": {},
  "capabilities": {},
  "assignments": {},
  "performance_metrics": {},
  "last_updated": ""
}
EOF

    # Create task assignment engine
    cat > "$integration_dir/task-assignment.sh" << 'EOF'
#!/bin/bash
# Agent-ATHMS Task Assignment Engine

INTEGRATION_DIR="$(dirname "$0")"
ATHMS_ROOT="$INTEGRATION_DIR/.."

assign_task_to_agent() {
    local task_id="$1"
    local agent_type="$2"
    local priority="$3"
    
    local task_path="$ATHMS_ROOT/active/$task_id"
    local assignment_id="$(date +%s)-$task_id"
    
    if [ ! -d "$task_path" ]; then
        echo "‚ùå Task $task_id not found in active tasks"
        return 1
    fi
    
    # Create assignment record
    jq -n \
        --arg task_id "$task_id" \
        --arg agent_type "$agent_type" \
        --arg priority "$priority" \
        --arg assigned_at "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
        --arg status "assigned" \
        '{
            task_id: $task_id,
            agent_type: $agent_type,
            priority: $priority,
            assigned_at: $assigned_at,
            status: $status,
            progress: 0,
            evidence_collected: [],
            last_update: $assigned_at
        }' > "$INTEGRATION_DIR/assignments/$assignment_id.json"
    
    # Update task status
    jq '.assignment = {
        assignment_id: "'$assignment_id'",
        agent_type: "'$agent_type'",
        assigned_at: "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'",
        status: "assigned"
    }' "$task_path/task.json" > "$task_path/task.json.tmp" && mv "$task_path/task.json.tmp" "$task_path/task.json"
    
    echo "‚úÖ Task $task_id assigned to $agent_type agent (Assignment: $assignment_id)"
    return 0
}

auto_assign_available_tasks() {
    echo "üîÑ Auto-assigning available tasks..."
    
    local assigned_count=0
    for task_dir in "$ATHMS_ROOT/active"/*; do
        if [ -d "$task_dir" ]; then
            local task_id=$(basename "$task_dir")
            local task_json="$task_dir/task.json"
            
            if [ -f "$task_json" ]; then
                local has_assignment=$(jq -r '.assignment // empty' "$task_json")
                local dependencies_met=$(jq -r '.dependencies_met // false' "$task_json")
                
                if [ -z "$has_assignment" ] && [ "$dependencies_met" = "true" ]; then
                    local task_type=$(jq -r '.task_type // "general"' "$task_json")
                    local priority=$(jq -r '.priority // "medium"' "$task_json")
                    
                    case "$task_type" in
                        "security"|"audit") assign_task_to_agent "$task_id" "security" "$priority" ;;
                        "qa"|"test"|"validation") assign_task_to_agent "$task_id" "qa" "$priority" ;;
                        "documentation"|"docs") assign_task_to_agent "$task_id" "documentation" "$priority" ;;
                        "integration"|"api") assign_task_to_agent "$task_id" "integration" "$priority" ;;
                        *) assign_task_to_agent "$task_id" "general" "$priority" ;;
                    esac
                    
                    if [ $? -eq 0 ]; then
                        ((assigned_count++))
                    fi
                fi
            fi
        fi
    done
    
    echo "üìä Auto-assigned $assigned_count tasks to agents"
}

monitor_agent_progress() {
    echo "üìà Monitoring agent progress..."
    
    local total_assignments=0
    local completed_assignments=0
    local failed_assignments=0
    
    for assignment_file in "$INTEGRATION_DIR/assignments"/*.json; do
        if [ -f "$assignment_file" ]; then
            ((total_assignments++))
            local status=$(jq -r '.status' "$assignment_file")
            case "$status" in
                "completed") ((completed_assignments++)) ;;
                "failed") ((failed_assignments++)) ;;
            esac
        fi
    done
    
    echo "üìä Agent Assignment Status:"
    echo "  Total: $total_assignments"
    echo "  Completed: $completed_assignments"
    echo "  Failed: $failed_assignments"
    echo "  Active: $((total_assignments - completed_assignments - failed_assignments))"
}

case "${1:-help}" in
    assign)
        assign_task_to_agent "$2" "$3" "${4:-medium}"
        ;;
    auto)
        auto_assign_available_tasks
        ;;
    monitor)
        monitor_agent_progress
        ;;
    *)
        echo "Usage: $0 {assign|auto|monitor}"
        echo "  assign <task_id> <agent_type> [priority]"
        echo "  auto - Auto-assign available tasks"
        echo "  monitor - Show agent progress"
        ;;
esac
EOF

    chmod +x "$integration_dir/task-assignment.sh"
    
    # Create agent progress reporting system
    cat > "$integration_dir/agent-progress.sh" << 'EOF'
#!/bin/bash
# Agent Progress Reporting System

INTEGRATION_DIR="$(dirname "$0")"
ATHMS_ROOT="$INTEGRATION_DIR/.."

report_progress() {
    local assignment_id="$1"
    local progress_percent="$2"
    local evidence_path="$3"
    local notes="$4"
    
    local assignment_file="$INTEGRATION_DIR/assignments/$assignment_id.json"
    
    if [ ! -f "$assignment_file" ]; then
        echo "‚ùå Assignment $assignment_id not found"
        return 1
    fi
    
    # Update assignment progress
    jq \
        --arg progress "$progress_percent" \
        --arg evidence "$evidence_path" \
        --arg notes "$notes" \
        --arg timestamp "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
        '.progress = ($progress | tonumber) |
         .evidence_collected += [$evidence] |
         .notes = $notes |
         .last_update = $timestamp' \
        "$assignment_file" > "$assignment_file.tmp" && mv "$assignment_file.tmp" "$assignment_file"
    
    # Update task progress
    local task_id=$(jq -r '.task_id' "$assignment_file")
    local task_path="$ATHMS_ROOT/active/$task_id"
    
    if [ -d "$task_path" ]; then
        jq \
            --arg progress "$progress_percent" \
            --arg timestamp "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
            '.assignment.progress = ($progress | tonumber) |
             .assignment.last_update = $timestamp' \
            "$task_path/task.json" > "$task_path/task.json.tmp" && mv "$task_path/task.json.tmp" "$task_path/task.json"
    fi
    
    echo "‚úÖ Progress updated: $assignment_id ‚Üí $progress_percent%"
}

complete_assignment() {
    local assignment_id="$1"
    local evidence_path="$2"
    local completion_notes="$3"
    
    local assignment_file="$INTEGRATION_DIR/assignments/$assignment_id.json"
    
    if [ ! -f "$assignment_file" ]; then
        echo "‚ùå Assignment $assignment_id not found"
        return 1
    fi
    
    # Mark assignment as completed
    jq \
        --arg evidence "$evidence_path" \
        --arg notes "$completion_notes" \
        --arg timestamp "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
        '.status = "completed" |
         .progress = 100 |
         .evidence_collected += [$evidence] |
         .completion_notes = $notes |
         .completed_at = $timestamp |
         .last_update = $timestamp' \
        "$assignment_file" > "$assignment_file.tmp" && mv "$assignment_file.tmp" "$assignment_file"
    
    # Move task to completed
    local task_id=$(jq -r '.task_id' "$assignment_file")
    local task_path="$ATHMS_ROOT/active/$task_id"
    
    if [ -d "$task_path" ]; then
        # Update task status
        jq \
            --arg timestamp "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
            '.status = "completed" |
             .completed_at = $timestamp |
             .assignment.status = "completed" |
             .assignment.completed_at = $timestamp' \
            "$task_path/task.json" > "$task_path/task.json.tmp" && mv "$task_path/task.json.tmp" "$task_path/task.json"
        
        # Move to completed directory
        mv "$task_path" "$ATHMS_ROOT/completed/"
        echo "‚úÖ Task $task_id completed and moved to completed directory"
    fi
    
    echo "‚úÖ Assignment $assignment_id marked as completed"
}

case "${1:-help}" in
    progress)
        report_progress "$2" "$3" "$4" "$5"
        ;;
    complete)
        complete_assignment "$2" "$3" "$4"
        ;;
    *)
        echo "Usage: $0 {progress|complete}"
        echo "  progress <assignment_id> <percent> <evidence_path> [notes]"
        echo "  complete <assignment_id> <evidence_path> [notes]"
        ;;
esac
EOF

    chmod +x "$integration_dir/agent-progress.sh"
    
    log_success "Agent-ATHMS Integration Bridge implemented"
    echo "üìÅ Integration components created in: $integration_dir"
    echo "üîß Task assignment: $integration_dir/task-assignment.sh"
    echo "üìä Progress reporting: $integration_dir/agent-progress.sh"
}

# Centralized State Management System
deploy_centralized_state() {
    print_section "Deploying Centralized State Management System"
    
    local state_dir="$TASK_ROOT/state"
    mkdir -p "$state_dir"/{global,projects,agents,coordination}
    
    # Create global state schema
    cat > "$state_dir/global-state.json" << 'EOF'
{
  "framework_version": "2.1.0",
  "deployment_timestamp": "",
  "active_projects": {},
  "global_agents": {},
  "coordination_status": {
    "total_active_tasks": 0,
    "total_agents": 0,
    "system_health": "healthy"
  },
  "integration_points": {
    "athms_enabled": true,
    "agent_bridge_enabled": true,
    "cicd_integration": false,
    "monitoring_enabled": false
  },
  "last_updated": ""
}
EOF

    # Create state synchronization engine
    cat > "$state_dir/state-sync.sh" << 'EOF'
#!/bin/bash
# Centralized State Synchronization Engine

STATE_DIR="$(dirname "$0")"
GLOBAL_STATE="$STATE_DIR/global-state.json"
USER_TONY_DIR="$HOME/.claude/tony"

sync_global_state() {
    echo "üîÑ Synchronizing global Tony state..."
    
    local timestamp=$(date -u +%Y-%m-%dT%H:%M:%SZ)
    
    # Update deployment timestamp if not set
    if [ "$(jq -r '.deployment_timestamp' "$GLOBAL_STATE")" = "null" ] || [ "$(jq -r '.deployment_timestamp' "$GLOBAL_STATE")" = "" ]; then
        jq --arg timestamp "$timestamp" '.deployment_timestamp = $timestamp' "$GLOBAL_STATE" > "$GLOBAL_STATE.tmp" && mv "$GLOBAL_STATE.tmp" "$GLOBAL_STATE"
    fi
    
    # Count active projects
    local project_count=0
    if [ -d "$USER_TONY_DIR/projects" ]; then
        project_count=$(find "$USER_TONY_DIR/projects" -maxdepth 1 -type d | wc -l)
        ((project_count--)) # Remove the projects directory itself
    fi
    
    # Count active agents
    local agent_count=0
    for project_dir in "$USER_TONY_DIR/projects"/*; do
        if [ -d "$project_dir/logs/agent-tasks" ]; then
            local project_agents=$(find "$project_dir/logs/agent-tasks" -maxdepth 1 -type d | wc -l)
            ((project_agents--)) # Remove the agent-tasks directory itself
            agent_count=$((agent_count + project_agents))
        fi
    done
    
    # Update global state
    jq \
        --arg timestamp "$timestamp" \
        --arg project_count "$project_count" \
        --arg agent_count "$agent_count" \
        '.coordination_status.total_active_tasks = 0 |
         .coordination_status.total_agents = ($agent_count | tonumber) |
         .coordination_status.system_health = "healthy" |
         .last_updated = $timestamp' \
        "$GLOBAL_STATE" > "$GLOBAL_STATE.tmp" && mv "$GLOBAL_STATE.tmp" "$GLOBAL_STATE"
    
    echo "‚úÖ Global state synchronized"
    echo "üìä Projects: $project_count, Agents: $agent_count"
}

register_project() {
    local project_name="$1"
    local project_path="$2"
    
    echo "üìù Registering project: $project_name"
    
    local timestamp=$(date -u +%Y-%m-%dT%H:%M:%SZ)
    
    # Register project in global state
    jq \
        --arg project "$project_name" \
        --arg path "$project_path" \
        --arg timestamp "$timestamp" \
        '.active_projects[$project] = {
            path: $path,
            registered_at: $timestamp,
            status: "active",
            last_activity: $timestamp
        } |
        .last_updated = $timestamp' \
        "$GLOBAL_STATE" > "$GLOBAL_STATE.tmp" && mv "$GLOBAL_STATE.tmp" "$GLOBAL_STATE"
    
    # Create project state file
    local project_state="$STATE_DIR/projects/$project_name.json"
    mkdir -p "$(dirname "$project_state")"
    
    jq -n \
        --arg project "$project_name" \
        --arg path "$project_path" \
        --arg timestamp "$timestamp" \
        '{
            project_name: $project,
            project_path: $path,
            registered_at: $timestamp,
            status: "active",
            athms_enabled: false,
            active_agents: {},
            task_summary: {
                total_tasks: 0,
                completed_tasks: 0,
                failed_tasks: 0
            },
            last_updated: $timestamp
        }' > "$project_state"
    
    echo "‚úÖ Project $project_name registered"
}

register_agent() {
    local project_name="$1"
    local agent_name="$2"
    local agent_type="$3"
    
    echo "ü§ñ Registering agent: $agent_name ($agent_type)"
    
    local timestamp=$(date -u +%Y-%m-%dT%H:%M:%SZ)
    local project_state="$STATE_DIR/projects/$project_name.json"
    
    if [ ! -f "$project_state" ]; then
        echo "‚ùå Project $project_name not registered"
        return 1
    fi
    
    # Register agent in project state
    jq \
        --arg agent "$agent_name" \
        --arg type "$agent_type" \
        --arg timestamp "$timestamp" \
        '.active_agents[$agent] = {
            agent_type: $type,
            registered_at: $timestamp,
            status: "active",
            assigned_tasks: [],
            last_activity: $timestamp
        } |
        .last_updated = $timestamp' \
        "$project_state" > "$project_state.tmp" && mv "$project_state.tmp" "$project_state"
    
    # Create agent state file
    local agent_state="$STATE_DIR/agents/$project_name-$agent_name.json"
    mkdir -p "$(dirname "$agent_state")"
    
    jq -n \
        --arg project "$project_name" \
        --arg agent "$agent_name" \
        --arg type "$agent_type" \
        --arg timestamp "$timestamp" \
        '{
            project_name: $project,
            agent_name: $agent,
            agent_type: $type,
            registered_at: $timestamp,
            status: "active",
            current_task: null,
            task_history: [],
            performance_metrics: {
                tasks_completed: 0,
                tasks_failed: 0,
                average_completion_time: 0
            },
            last_updated: $timestamp
        }' > "$agent_state"
    
    echo "‚úÖ Agent $agent_name registered"
}

get_system_status() {
    echo "üìä Tony Framework System Status"
    echo "================================"
    
    if [ ! -f "$GLOBAL_STATE" ]; then
        echo "‚ùå Global state not found"
        return 1
    fi
    
    local framework_version=$(jq -r '.framework_version' "$GLOBAL_STATE")
    local deployment_time=$(jq -r '.deployment_timestamp' "$GLOBAL_STATE")
    local project_count=$(jq -r '.active_projects | length' "$GLOBAL_STATE")
    local agent_count=$(jq -r '.coordination_status.total_agents' "$GLOBAL_STATE")
    local system_health=$(jq -r '.coordination_status.system_health' "$GLOBAL_STATE")
    
    echo "Framework Version: $framework_version"
    echo "Deployment Time: $deployment_time"
    echo "Active Projects: $project_count"
    echo "Active Agents: $agent_count"
    echo "System Health: $system_health"
    
    echo ""
    echo "Integration Status:"
    local athms_enabled=$(jq -r '.integration_points.athms_enabled' "$GLOBAL_STATE")
    local bridge_enabled=$(jq -r '.integration_points.agent_bridge_enabled' "$GLOBAL_STATE")
    local cicd_enabled=$(jq -r '.integration_points.cicd_integration' "$GLOBAL_STATE")
    local monitoring_enabled=$(jq -r '.integration_points.monitoring_enabled' "$GLOBAL_STATE")
    
    echo "  ATHMS: $athms_enabled"
    echo "  Agent Bridge: $bridge_enabled"
    echo "  CI/CD Integration: $cicd_enabled"
    echo "  Monitoring: $monitoring_enabled"
}

case "${1:-help}" in
    sync)
        sync_global_state
        ;;
    register-project)
        register_project "$2" "$3"
        ;;
    register-agent)
        register_agent "$2" "$3" "$4"
        ;;
    status)
        get_system_status
        ;;
    *)
        echo "Usage: $0 {sync|register-project|register-agent|status}"
        echo "  sync - Synchronize global state"
        echo "  register-project <name> <path>"
        echo "  register-agent <project> <agent> <type>"
        echo "  status - Show system status"
        ;;
esac
EOF

    chmod +x "$state_dir/state-sync.sh"
    
    # Initialize global state
    "$state_dir/state-sync.sh" sync
    
    log_success "Centralized State Management System deployed"
    echo "üìÅ State management components: $state_dir"
    echo "üîß State synchronization: $state_dir/state-sync.sh"
}

# CI/CD Integration Layer
deploy_cicd_integration() {
    print_section "Deploying CI/CD Integration Layer"
    
    local cicd_dir="$TASK_ROOT/cicd"
    mkdir -p "$cicd_dir"/{pipelines,evidence,monitoring,webhooks}
    
    # Create CI/CD evidence validation engine
    cat > "$cicd_dir/evidence-validator.sh" << 'EOF'
#!/bin/bash
# CI/CD Evidence Validation Engine

CICD_DIR="$(dirname "$0")"
ATHMS_ROOT="$CICD_DIR/.."

validate_build_evidence() {
    local task_id="$1"
    local build_status="$2"
    local build_url="$3"
    local test_coverage="$4"
    
    echo "üîç Validating build evidence for task: $task_id"
    
    local task_path="$ATHMS_ROOT/active/$task_id"
    local evidence_dir="$task_path/evidence"
    
    if [ ! -d "$task_path" ]; then
        echo "‚ùå Task $task_id not found"
        return 1
    fi
    
    mkdir -p "$evidence_dir"
    
    # Create build evidence record
    local timestamp=$(date -u +%Y-%m-%dT%H:%M:%SZ)
    local evidence_file="$evidence_dir/build-evidence-$timestamp.json"
    
    jq -n \
        --arg task_id "$task_id" \
        --arg build_status "$build_status" \
        --arg build_url "$build_url" \
        --arg coverage "$test_coverage" \
        --arg timestamp "$timestamp" \
        '{
            task_id: $task_id,
            evidence_type: "build_validation",
            build_status: $build_status,
            build_url: $build_url,
            test_coverage: ($coverage | tonumber),
            validation_timestamp: $timestamp,
            validation_result: (if $build_status == "success" and ($coverage | tonumber) >= 80 then "passed" else "failed" end),
            requirements_met: {
                build_successful: ($build_status == "success"),
                coverage_threshold: (($coverage | tonumber) >= 80),
                integration_tests: true
            }
        }' > "$evidence_file"
    
    local validation_result=$(jq -r '.validation_result' "$evidence_file")
    
    if [ "$validation_result" = "passed" ]; then
        echo "‚úÖ Build evidence validation PASSED"
        
        # Update task with successful evidence
        jq \
            --arg timestamp "$timestamp" \
            --arg evidence_file "$(basename "$evidence_file")" \
            '.evidence_validation.build = {
                status: "validated",
                evidence_file: $evidence_file,
                validated_at: $timestamp
            } |
            .last_updated = $timestamp' \
            "$task_path/task.json" > "$task_path/task.json.tmp" && mv "$task_path/task.json.tmp" "$task_path/task.json"
        
        return 0
    else
        echo "‚ùå Build evidence validation FAILED"
        echo "   Build Status: $build_status"
        echo "   Test Coverage: $test_coverage%"
        return 1
    fi
}

create_pipeline_integration() {
    local project_name="$1"
    local pipeline_type="$2"  # github, gitlab, jenkins, etc.
    
    echo "üîß Creating $pipeline_type pipeline integration for $project_name"
    
    local pipeline_config="$CICD_DIR/pipelines/$project_name-$pipeline_type.yml"
    
    case "$pipeline_type" in
        "github")
            cat > "$pipeline_config" << 'PIPELINE_EOF'
name: Tony Framework Integration

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  tony-validation:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Run tests with coverage
      run: npm run test:coverage
    
    - name: Build application
      run: npm run build
    
    - name: Tony Evidence Collection
      run: |
        # Extract test coverage
        COVERAGE=$(cat coverage/coverage-summary.json | jq -r '.total.lines.pct')
        
        # Report to Tony ATHMS
        if [ -f "./scripts/tony-tasks.sh" ]; then
          ./scripts/tony-tasks.sh cicd validate-build \
            --task-id="$GITHUB_SHA" \
            --build-status="success" \
            --build-url="$GITHUB_SERVER_URL/$GITHUB_REPOSITORY/actions/runs/$GITHUB_RUN_ID" \
            --coverage="$COVERAGE"
        fi
    
    - name: Tony Task Completion
      if: success()
      run: |
        if [ -f "./scripts/tony-tasks.sh" ]; then
          ./scripts/tony-tasks.sh cicd complete-task --task-id="$GITHUB_SHA"
        fi
PIPELINE_EOF
            ;;
        "gitlab")
            cat > "$pipeline_config" << 'PIPELINE_EOF'
stages:
  - test
  - build
  - tony-integration

variables:
  NODE_VERSION: "18"

test:
  stage: test
  image: node:$NODE_VERSION
  script:
    - npm ci
    - npm run test:coverage
  artifacts:
    reports:
      coverage: coverage/clover.xml
    paths:
      - coverage/

build:
  stage: build
  image: node:$NODE_VERSION
  script:
    - npm ci
    - npm run build
  artifacts:
    paths:
      - dist/

tony-validation:
  stage: tony-integration
  image: alpine:latest
  before_script:
    - apk add --no-cache jq bash
  script:
    - |
      # Extract test coverage
      COVERAGE=$(cat coverage/coverage-summary.json | jq -r '.total.lines.pct')
      
      # Report to Tony ATHMS
      if [ -f "./scripts/tony-tasks.sh" ]; then
        ./scripts/tony-tasks.sh cicd validate-build \
          --task-id="$CI_COMMIT_SHA" \
          --build-status="success" \
          --build-url="$CI_PIPELINE_URL" \
          --coverage="$COVERAGE"
      fi
  dependencies:
    - test
    - build
PIPELINE_EOF
            ;;
    esac
    
    echo "‚úÖ Pipeline configuration created: $pipeline_config"
}

monitor_pipeline_status() {
    echo "üìà Monitoring CI/CD pipeline status..."
    
    local active_validations=0
    local passed_validations=0
    local failed_validations=0
    
    for task_dir in "$ATHMS_ROOT/active"/*; do
        if [ -d "$task_dir" ]; then
            local evidence_dir="$task_dir/evidence"
            if [ -d "$evidence_dir" ]; then
                for evidence_file in "$evidence_dir"/build-evidence-*.json; do
                    if [ -f "$evidence_file" ]; then
                        ((active_validations++))
                        local result=$(jq -r '.validation_result' "$evidence_file")
                        case "$result" in
                            "passed") ((passed_validations++)) ;;
                            "failed") ((failed_validations++)) ;;
                        esac
                    fi
                done
            fi
        fi
    done
    
    echo "üìä CI/CD Integration Status:"
    echo "  Total Validations: $active_validations"
    echo "  Passed: $passed_validations"
    echo "  Failed: $failed_validations"
    echo "  Success Rate: $(( passed_validations * 100 / (active_validations > 0 ? active_validations : 1) ))%"
}

setup_webhook_handlers() {
    echo "ü™ù Setting up CI/CD webhook handlers..."
    
    local webhook_script="$CICD_DIR/webhooks/webhook-handler.sh"
    
    cat > "$webhook_script" << 'WEBHOOK_EOF'
#!/bin/bash
# CI/CD Webhook Handler for Tony Framework

WEBHOOK_DIR="$(dirname "$0")"
CICD_DIR="$(dirname "$WEBHOOK_DIR")"

handle_github_webhook() {
    local payload="$1"
    
    echo "üì® Processing GitHub webhook..."
    
    local action=$(echo "$payload" | jq -r '.action // empty')
    local status=$(echo "$payload" | jq -r '.status // .state // empty')
    local commit_sha=$(echo "$payload" | jq -r '.sha // .head_commit.id // empty')
    
    case "$action" in
        "completed")
            if [ "$status" = "success" ]; then
                echo "‚úÖ GitHub Action completed successfully for $commit_sha"
                # Update Tony ATHMS with success
                "$CICD_DIR/evidence-validator.sh" validate-build "$commit_sha" "success" "" "85"
            else
                echo "‚ùå GitHub Action failed for $commit_sha"
                # Update Tony ATHMS with failure
                "$CICD_DIR/evidence-validator.sh" validate-build "$commit_sha" "failed" "" "0"
            fi
            ;;
    esac
}

handle_gitlab_webhook() {
    local payload="$1"
    
    echo "üì® Processing GitLab webhook..."
    
    local status=$(echo "$payload" | jq -r '.object_attributes.status // empty')
    local commit_sha=$(echo "$payload" | jq -r '.sha // .object_attributes.sha // empty')
    
    case "$status" in
        "success")
            echo "‚úÖ GitLab pipeline completed successfully for $commit_sha"
            "$CICD_DIR/evidence-validator.sh" validate-build "$commit_sha" "success" "" "85"
            ;;
        "failed")
            echo "‚ùå GitLab pipeline failed for $commit_sha"
            "$CICD_DIR/evidence-validator.sh" validate-build "$commit_sha" "failed" "" "0"
            ;;
    esac
}

case "${1:-help}" in
    github)
        handle_github_webhook "$2"
        ;;
    gitlab)
        handle_gitlab_webhook "$2"
        ;;
    *)
        echo "Usage: $0 {github|gitlab} <payload>"
        ;;
esac
WEBHOOK_EOF
    
    chmod +x "$webhook_script"
    echo "‚úÖ Webhook handlers configured"
}

case "${1:-help}" in
    validate-build)
        validate_build_evidence "$2" "$3" "$4" "$5"
        ;;
    create-pipeline)
        create_pipeline_integration "$2" "$3"
        ;;
    monitor)
        monitor_pipeline_status
        ;;
    webhook)
        setup_webhook_handlers
        ;;
    *)
        echo "Usage: $0 {validate-build|create-pipeline|monitor|webhook}"
        echo "  validate-build <task_id> <status> <url> <coverage>"
        echo "  create-pipeline <project> <type>"
        echo "  monitor - Show pipeline status"
        echo "  webhook - Setup webhook handlers"
        ;;
esac
EOF

    chmod +x "$cicd_dir/evidence-validator.sh"
    
    # Setup initial webhook handlers
    "$cicd_dir/evidence-validator.sh" webhook
    
    # Update global state to enable CI/CD integration
    local state_sync="$TASK_ROOT/state/state-sync.sh"
    if [ -f "$state_sync" ]; then
        local global_state="$TASK_ROOT/state/global-state.json"
        jq '.integration_points.cicd_integration = true' "$global_state" > "$global_state.tmp" && mv "$global_state.tmp" "$global_state"
    fi
    
    log_success "CI/CD Integration Layer deployed"
    echo "üìÅ CI/CD components: $cicd_dir"
    echo "üîß Evidence validator: $cicd_dir/evidence-validator.sh"
    echo "ü™ù Webhook handlers: $cicd_dir/webhooks/"
}

# Cross-Project State Synchronization
deploy_cross_project_sync() {
    print_section "Deploying Cross-Project State Synchronization"
    
    local sync_dir="$TASK_ROOT/sync"
    mkdir -p "$sync_dir"/{projects,federation,monitoring}
    
    # Create cross-project synchronization engine
    cat > "$sync_dir/project-sync.sh" << 'EOF'
#!/bin/bash
# Cross-Project State Synchronization Engine

SYNC_DIR="$(dirname "$0")"
ATHMS_ROOT="$SYNC_DIR/.."
USER_TONY_DIR="$HOME/.claude/tony"

sync_all_projects() {
    echo "üåê Synchronizing state across all Tony projects..."
    
    local sync_timestamp=$(date -u +%Y-%m-%dT%H:%M:%SZ)
    local total_projects=0
    local synced_projects=0
    local failed_syncs=0
    
    # Create federation state
    local federation_state="$SYNC_DIR/federation/global-federation.json"
    mkdir -p "$(dirname "$federation_state")"
    
    jq -n \
        --arg timestamp "$sync_timestamp" \
        '{
            sync_timestamp: $timestamp,
            federation_version: "1.0.0",
            projects: {},
            global_metrics: {
                total_tasks: 0,
                total_agents: 0,
                total_projects: 0,
                health_score: 100
            },
            last_sync: $timestamp
        }' > "$federation_state"
    
    # Discover and sync all Tony-enabled projects
    if [ -d "$USER_TONY_DIR/projects" ]; then
        for project_dir in "$USER_TONY_DIR/projects"/*; do
            if [ -d "$project_dir" ]; then
                ((total_projects++))
                local project_name=$(basename "$project_dir")
                
                echo "üîÑ Syncing project: $project_name"
                
                if sync_single_project "$project_name" "$project_dir"; then
                    ((synced_projects++))
                    echo "‚úÖ $project_name synchronized"
                else
                    ((failed_syncs++))
                    echo "‚ùå Failed to sync $project_name"
                fi
            fi
        done
    fi
    
    # Update federation statistics
    jq \
        --arg total "$total_projects" \
        --arg synced "$synced_projects" \
        --arg failed "$failed_syncs" \
        --arg timestamp "$sync_timestamp" \
        '.global_metrics.total_projects = ($total | tonumber) |
         .global_metrics.synced_projects = ($synced | tonumber) |
         .global_metrics.failed_syncs = ($failed | tonumber) |
         .global_metrics.health_score = (($synced | tonumber) * 100 / (($total | tonumber) > 0 ? ($total | tonumber) : 1)) |
         .last_sync = $timestamp' \
        "$federation_state" > "$federation_state.tmp" && mv "$federation_state.tmp" "$federation_state"
    
    echo "üìä Cross-project sync complete:"
    echo "  Total Projects: $total_projects"
    echo "  Synced: $synced_projects"
    echo "  Failed: $failed_syncs"
    echo "  Health Score: $(jq -r '.global_metrics.health_score' "$federation_state")%"
}

sync_single_project() {
    local project_name="$1"
    local project_path="$2"
    
    local project_sync_file="$SYNC_DIR/projects/$project_name.json"
    mkdir -p "$(dirname "$project_sync_file")"
    
    # Check if project has Tony infrastructure
    local tony_script="$project_path/scripts/tony-tasks.sh"
    local athms_exists=false
    local task_count=0
    local agent_count=0
    
    if [ -f "$tony_script" ]; then
        athms_exists=true
        
        # Count tasks if ATHMS is deployed
        local project_task_dir="$project_path/docs/task-management"
        if [ -d "$project_task_dir/active" ]; then
            task_count=$(find "$project_task_dir/active" -maxdepth 1 -type d | wc -l)
            ((task_count--)) # Remove active directory itself
        fi
        
        # Count agents
        if [ -d "$project_path/logs/agent-tasks" ]; then
            agent_count=$(find "$project_path/logs/agent-tasks" -maxdepth 1 -type d | wc -l)
            ((agent_count--)) # Remove agent-tasks directory itself
        fi
    fi
    
    # Create project sync record
    local timestamp=$(date -u +%Y-%m-%dT%H:%M:%SZ)
    
    jq -n \
        --arg project "$project_name" \
        --arg path "$project_path" \
        --arg timestamp "$timestamp" \
        --arg athms_exists "$athms_exists" \
        --arg task_count "$task_count" \
        --arg agent_count "$agent_count" \
        '{
            project_name: $project,
            project_path: $path,
            sync_timestamp: $timestamp,
            tony_enabled: ($athms_exists | test("true")),
            metrics: {
                active_tasks: ($task_count | tonumber),
                active_agents: ($agent_count | tonumber),
                health_status: (if ($athms_exists | test("true")) then "healthy" else "not_deployed" end)
            },
            integration_status: {
                athms_deployed: ($athms_exists | test("true")),
                state_sync_enabled: true,
                last_activity: $timestamp
            }
        }' > "$project_sync_file"
    
    # Update federation state with project data
    local federation_state="$SYNC_DIR/federation/global-federation.json"
    if [ -f "$federation_state" ]; then
        jq \
            --arg project "$project_name" \
            --arg path "$project_path" \
            --arg timestamp "$timestamp" \
            --arg task_count "$task_count" \
            --arg agent_count "$agent_count" \
            '.projects[$project] = {
                path: $path,
                last_sync: $timestamp,
                active_tasks: ($task_count | tonumber),
                active_agents: ($agent_count | tonumber),
                status: "synchronized"
            } |
            .global_metrics.total_tasks += ($task_count | tonumber) |
            .global_metrics.total_agents += ($agent_count | tonumber)' \
            "$federation_state" > "$federation_state.tmp" && mv "$federation_state.tmp" "$federation_state"
    fi
    
    return 0
}

propagate_user_changes() {
    echo "üì° Propagating user-level changes to all projects..."
    
    local user_templates="$USER_TONY_DIR/templates"
    local user_config="$USER_TONY_DIR/config"
    local changes_propagated=0
    
    if [ -d "$USER_TONY_DIR/projects" ]; then
        for project_dir in "$USER_TONY_DIR/projects"/*; do
            if [ -d "$project_dir" ]; then
                local project_name=$(basename "$project_dir")
                echo "üîÑ Propagating to $project_name..."
                
                # Update project templates if user templates are newer
                if [ -d "$user_templates" ] && [ -d "$project_dir/docs/agent-management" ]; then
                    rsync -au "$user_templates/" "$project_dir/docs/agent-management/templates/" 2>/dev/null && {
                        echo "‚úÖ Templates updated for $project_name"
                        ((changes_propagated++))
                    }
                fi
                
                # Update project configuration
                if [ -f "$user_config/global-settings.json" ] && [ -d "$project_dir/.claude" ]; then
                    cp "$user_config/global-settings.json" "$project_dir/.claude/global-settings.json" 2>/dev/null && {
                        echo "‚úÖ Configuration updated for $project_name"
                    }
                fi
            fi
        done
    fi
    
    echo "üìä Propagated changes to $changes_propagated projects"
}

monitor_federation_health() {
    echo "üíì Monitoring Tony Federation Health..."
    
    local federation_state="$SYNC_DIR/federation/global-federation.json"
    
    if [ ! -f "$federation_state" ]; then
        echo "‚ùå Federation state not found"
        return 1
    fi
    
    local total_projects=$(jq -r '.global_metrics.total_projects' "$federation_state")
    local total_tasks=$(jq -r '.global_metrics.total_tasks' "$federation_state")
    local total_agents=$(jq -r '.global_metrics.total_agents' "$federation_state")
    local health_score=$(jq -r '.global_metrics.health_score' "$federation_state")
    local last_sync=$(jq -r '.last_sync' "$federation_state")
    
    echo "üåê Tony Federation Status:"
    echo "  Projects: $total_projects"
    echo "  Active Tasks: $total_tasks"
    echo "  Active Agents: $total_agents"
    echo "  Health Score: $health_score%"
    echo "  Last Sync: $last_sync"
    
    # Check for unhealthy projects
    local unhealthy_projects=()
    while IFS= read -r project; do
        if [ -n "$project" ]; then
            unhealthy_projects+=("$project")
        fi
    done < <(jq -r '.projects | to_entries[] | select(.value.status != "synchronized") | .key' "$federation_state" 2>/dev/null)
    
    if [ ${#unhealthy_projects[@]} -gt 0 ]; then
        echo "‚ö†Ô∏è  Unhealthy Projects: ${unhealthy_projects[*]}"
    fi
    
    # Health threshold check
    if [ "$(echo "$health_score < 90" | bc 2>/dev/null || echo 0)" = "1" ]; then
        echo "üö® FEDERATION HEALTH WARNING: Score below 90%"
        return 1
    fi
    
    echo "‚úÖ Federation health: GOOD"
    return 0
}

case "${1:-help}" in
    sync-all)
        sync_all_projects
        ;;
    sync-project)
        sync_single_project "$2" "$3"
        ;;
    propagate)
        propagate_user_changes
        ;;
    health)
        monitor_federation_health
        ;;
    *)
        echo "Usage: $0 {sync-all|sync-project|propagate|health}"
        echo "  sync-all - Synchronize all Tony projects"
        echo "  sync-project <name> <path> - Sync specific project"
        echo "  propagate - Propagate user-level changes"
        echo "  health - Monitor federation health"
        ;;
esac
EOF

    chmod +x "$sync_dir/project-sync.sh"
    
    # Create monitoring dashboard
    cat > "$sync_dir/monitoring/federation-monitor.sh" << 'EOF'
#!/bin/bash
# Federation Monitoring Dashboard

MONITOR_DIR="$(dirname "$0")"
SYNC_DIR="$(dirname "$MONITOR_DIR")"

generate_federation_report() {
    echo "üìä Generating Tony Federation Report..."
    
    local report_file="$MONITOR_DIR/federation-report-$(date +%Y%m%d-%H%M).md"
    local federation_state="$SYNC_DIR/federation/global-federation.json"
    
    if [ ! -f "$federation_state" ]; then
        echo "‚ùå Federation state not found"
        return 1
    fi
    
    cat > "$report_file" << REPORT_EOF
# Tony Framework Federation Report
Generated: $(date -u +"%Y-%m-%d %H:%M:%S UTC")

## Executive Summary
$(jq -r '
"- **Total Projects**: " + (.global_metrics.total_projects | tostring) + "\n" +
"- **Active Tasks**: " + (.global_metrics.total_tasks | tostring) + "\n" +
"- **Active Agents**: " + (.global_metrics.total_agents | tostring) + "\n" +
"- **Health Score**: " + (.global_metrics.health_score | tostring) + "%\n" +
"- **Last Sync**: " + .last_sync
' "$federation_state")

## Project Details
$(jq -r '
.projects | to_entries[] | 
"### " + .key + "\n" +
"- **Path**: " + .value.path + "\n" +
"- **Status**: " + .value.status + "\n" +
"- **Tasks**: " + (.value.active_tasks | tostring) + "\n" +
"- **Agents**: " + (.value.active_agents | tostring) + "\n" +
"- **Last Sync**: " + .value.last_sync + "\n"
' "$federation_state")

## Health Analysis
$(if [ "$(jq -r '.global_metrics.health_score < 90' "$federation_state")" = "true" ]; then
    echo "üö® **WARNING**: Federation health below 90%"
    echo
    echo "**Recommended Actions**:"
    echo "1. Check failed project synchronizations"
    echo "2. Verify Tony deployment status across projects"
    echo "3. Review agent coordination efficiency"
else
    echo "‚úÖ **HEALTHY**: All systems operating normally"
fi)

## Synchronization Status
- **Sync Method**: Cross-project state federation
- **Sync Frequency**: On-demand with health monitoring
- **State Persistence**: JSON-based with backup/restore
- **Integration Points**: ATHMS, Agent Bridge, CI/CD Layer

REPORT_EOF

    echo "üìã Federation report generated: $report_file"
    
    # Show summary
    echo ""
    echo "üìä Current Federation Status:"
    jq -r '
    "Projects: " + (.global_metrics.total_projects | tostring) + "\n" +
    "Tasks: " + (.global_metrics.total_tasks | tostring) + "\n" +
    "Agents: " + (.global_metrics.total_agents | tostring) + "\n" +
    "Health: " + (.global_metrics.health_score | tostring) + "%"
    ' "$federation_state"
}

watch_federation() {
    echo "üëÅÔ∏è  Watching Tony Federation (Press Ctrl+C to stop)..."
    
    while true; do
        clear
        echo "üåê Tony Framework Federation Monitor"
        echo "=================================="
        echo "$(date)"
        echo
        
        "$SYNC_DIR/project-sync.sh" health
        
        echo
        echo "üîÑ Auto-refresh in 30 seconds..."
        sleep 30
    done
}

case "${1:-help}" in
    report)
        generate_federation_report
        ;;
    watch)
        watch_federation
        ;;
    *)
        echo "Usage: $0 {report|watch}"
        echo "  report - Generate federation status report"
        echo "  watch - Real-time federation monitoring"
        ;;
esac
EOF

    chmod +x "$sync_dir/monitoring/federation-monitor.sh"
    
    # Initialize federation state
    "$sync_dir/project-sync.sh" sync-all
    
    log_success "Cross-Project State Synchronization deployed"
    echo "üìÅ Sync components: $sync_dir"
    echo "üîß Project sync: $sync_dir/project-sync.sh"
    echo "üìä Federation monitor: $sync_dir/monitoring/federation-monitor.sh"
}

# Get next available task
get_next_task() {
    print_section "Finding Next Available Task"
    
    local available_tasks=()
    
    for task_dir in "$ACTIVE_DIR"/*; do
        if [ -d "$task_dir" ]; then
            local task_id status_file dependencies_file
            task_id=$(basename "$task_dir")
            status_file="$task_dir/status.json"
            dependencies_file="$task_dir/dependencies.json"
            
            if [ -f "$status_file" ] && [ -f "$dependencies_file" ]; then
                local status blocked prerequisites_count
                status=$(jq -r '.status' "$status_file")
                blocked=$(jq -r '.blocked' "$status_file")
                prerequisites_count=$(jq -r '.prerequisites | length' "$dependencies_file")
                
                # Task is available if: pending, not blocked, no prerequisites
                if [ "$status" = "pending" ] && [ "$blocked" = "false" ] && [ "$prerequisites_count" -eq 0 ]; then
                    available_tasks+=("$task_id")
                fi
            fi
        fi
    done
    
    if [ ${#available_tasks[@]} -eq 0 ]; then
        log_info "No tasks available for assignment"
        echo "üí° Possible reasons:"
        echo "  - All tasks are in progress or completed"
        echo "  - Available tasks have unmet dependencies"
        echo "  - Tasks are blocked"
        return 0
    fi
    
    echo "üìã Available Tasks (${#available_tasks[@]} found):"
    
    for task_id in "${available_tasks[@]}"; do
        local task_file="$ACTIVE_DIR/$task_id/task.json"
        local title
        title=$(jq -r '.title' "$task_file")
        echo "  üî∏ $task_id - $title"
    done
    
    echo ""
    echo "üí° To claim a task: $0 task claim <task-id>"
    echo "üí° To assign a task: $0 task assign <task-id> <agent-name>"
}

# Main execution
main() {
    parse_arguments "$@"
    
    case "$MODE" in
        "init")
            init_athms
            ;;
        "plan")
            case "${ARGS[0]:-}" in
                "start")
                    start_planning
                    ;;
                "continue")
                    continue_planning
                    ;;
                "abstract")
                    create_abstraction
                    ;;
                "decompose")
                    decompose_tree "${ARGS[1]:-}"
                    ;;
                "second-pass")
                    second_pass_analysis
                    ;;
                "validate")
                    validate_planning
                    ;;
                "metrics")
                    show_planning_metrics
                    ;;
                *)
                    log_error "Unknown planning command: ${ARGS[0]:-}"
                    show_usage
                    exit 1
                    ;;
            esac
            ;;
        "task")
            case "${ARGS[0]:-}" in
                "create")
                    create_task "${ARGS[1]:-}" "${ARGS[2]:-}"
                    ;;
                "status")
                    show_task_status "${ARGS[1]:-}"
                    ;;
                "assign")
                    assign_task "${ARGS[1]:-}" "${ARGS[2]:-}"
                    ;;
                "claim")
                    claim_task "${ARGS[1]:-}"
                    ;;
                "update")
                    update_task_status "${ARGS[1]:-}" "${ARGS[2]:-}"
                    ;;
                "complete")
                    complete_task "${ARGS[1]:-}"
                    ;;
                "validate")
                    validate_task "${ARGS[1]:-}"
                    ;;
                "recover")
                    recover_failed_tasks
                    ;;
                "next")
                    get_next_task
                    ;;
                *)
                    log_error "Unknown task command: ${ARGS[0]:-}"
                    show_usage
                    exit 1
                    ;;
            esac
            ;;
        "status")
            validate_planning
            ;;
        "backup")
            create_state_backup
            ;;
        "restore")
            restore_state_backup "${ARGS[0]:-}"
            ;;
        "validate")
            validate_state_integrity
            ;;
        "emergency")
            emergency_recovery
            ;;
        "report")
            generate_project_report
            ;;
        "cleanup")
            cleanup_completed_tasks
            ;;
        "integrate")
            integrate_agent_athms
            ;;
        "state")
            deploy_centralized_state
            ;;
        "cicd")
            deploy_cicd_integration
            ;;
        "sync")
            deploy_cross_project_sync
            ;;
        "security")
            deploy_enterprise_security
            ;;
        "dashboard")
            "$SCRIPT_DIR/tony-dashboard.sh" "${ARGS[@]}"
            ;;
        "force-upgrade")
            "$SCRIPT_DIR/tony-force-upgrade.sh" "${ARGS[@]}"
            ;;
        *)
            log_error "Unknown command: $MODE"
            show_usage
            exit 1
            ;;
    esac
}

# Deploy Enterprise Security Controls and Monitoring System
deploy_enterprise_security() {
    print_section "Enterprise Security System Deployment"
    
    log_info "Deploying enterprise security controls..."
    
    # Execute the security deployment script directly
    local security_script="$SCRIPT_DIR/security-enterprise.sh"
    
    if [ -f "$security_script" ]; then
        log_info "Executing enterprise security deployment..."
        
        # Execute the security script
        if "$security_script"; then
            log_success "Enterprise security system deployment completed"
        else
            log_error "Security deployment failed"
            exit 1
        fi
    else
        log_error "Security deployment script not found: $security_script"
        log_info "Please ensure security-enterprise.sh is in the scripts directory"
        exit 1
    fi
    
    # Display integration information
    print_subsection "Security Integration Status"
    echo "‚úÖ Access Control Framework: Deployed"
    echo "‚úÖ Vulnerability Scanner: Ready"
    echo "‚úÖ Security Monitor: Available"
    echo "‚úÖ Audit Logger: Active"
    echo "‚úÖ Compliance Reporter: Ready"
    echo "‚úÖ Security Agents: Coordinated"
    echo ""
    echo "Next steps:"
    echo "1. Start security monitoring: ./security/security-monitor.sh start"
    echo "2. Run initial vulnerability scan: ./security/vulnerability-scanner.sh"
    echo "3. Generate compliance report: ./security/compliance-reporter.sh generate"
    echo ""
}

# Execute main function with all arguments
main "$@"